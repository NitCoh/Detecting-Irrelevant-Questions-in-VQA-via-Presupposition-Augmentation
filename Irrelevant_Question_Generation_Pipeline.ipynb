{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C_77FNmnCcQ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "!pip install wandb\n",
        "!pip install happytransformer\n",
        "!pip install Levenshtein==0.20.3\n",
        "!pip install ijson\n",
        "!pip install spacy\n",
        "!pip install spacy-transformers\n",
        "!pip install lemminflect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inflect==5.6.2"
      ],
      "metadata": {
        "id": "2dYDwhVVPTSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from google.colab import drive\n",
        "import json\n",
        "import sys\n",
        "import csv\n",
        "import os, errno\n",
        "import base64\n",
        "import time\n",
        "import re\n",
        "import logging\n",
        "import copy\n",
        "from itertools import combinations, chain, product, groupby\n",
        "from datetime import datetime\n",
        "from timeit import default_timer as timer\n",
        "import datetime as dt\n",
        "from collections import OrderedDict, Counter\n",
        "from json import JSONEncoder\n",
        "\n",
        "import pickle\n",
        "import spacy\n",
        "import ijson\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from Levenshtein import distance as lev_dis\n",
        "from typing import List, Dict, Tuple, Iterable, Type, Union, Callable, Optional\n",
        "from scipy.special import softmax\n",
        "from happytransformer import HappyTextToText, TTSettings\n",
        "from transformers import DebertaForSequenceClassification, DebertaTokenizerFast\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch import Tensor\n",
        "import inflect\n",
        "from lemminflect import getLemma, getInflection\n",
        "\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "4MqG7d59B2er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "bpclVKz8G8qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "TSWzY1S4ZR-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use drive if your files are there\n",
        "# drive.mount('', force_remount=True)"
      ],
      "metadata": {
        "id": "52ndxILbN4FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inflect engine\n",
        "inflect_eng = inflect.engine()"
      ],
      "metadata": {
        "id": "THIwbq4sH-Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logger\n",
        "logger = None"
      ],
      "metadata": {
        "id": "G5-Y6rf6Kigu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_token = '<mask>'\n",
        "semantic = ['rel', 'relation']\n",
        "structural = ['query']\n",
        "\n",
        "#Populate the paths\n",
        "\n",
        "#path to Visual Genome Scene Graph Objects\n",
        "sg_ds_path = '.../Visual-Genome/scene_graphs.json'\n",
        "#path to Visual Genome images\n",
        "path_to_images = '.../Visual-Genome/VG_100K'\n",
        "#path to Visual Genome synset mapping\n",
        "synset_mapping_path = '.../visual_genome_object_synsets.json'\n",
        "#mass nouns\n",
        "mass_nouns_path = '.../mass_nouns.txt'\n",
        "\n",
        "#this file pre-processed to ease the pipeline. produced from VG files.\n",
        "subj_obj_2_rels_path = \".../subject_object_to_relations.json\"\n"
      ],
      "metadata": {
        "id": "gf9_S4ThJkIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inner Modules"
      ],
      "metadata": {
        "id": "pNz8mg4VXkLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Global Utils"
      ],
      "metadata": {
        "id": "0rtuMAT6YGZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_timing(f, *args, **kwargs):\n",
        "    start = timer()\n",
        "    ret = f(*args, **kwargs)\n",
        "    end = timer()\n",
        "    logger.debug(f\"-- Function {f.__name__} Time taken: {end - start} sec\")\n",
        "    return ret\n",
        "\n",
        "\n",
        "def image_id_to_scene_graph(path):\n",
        "    ret = dict()\n",
        "    start = timer()\n",
        "    with open(path) as f:\n",
        "        items = ijson.items(f, \"item\")\n",
        "        for item in items:\n",
        "            if \"image_id\" in item:\n",
        "                img_id = item[\"image_id\"]\n",
        "                if img_id in ret:\n",
        "                    print(f\"{img_id} is already mapped\")\n",
        "                else:\n",
        "                    ret[img_id] = item\n",
        "    print(f\"Time taken generating scene graph mapping: {timer() - start} sec\")\n",
        "    return ret\n",
        "\n",
        "\n",
        "def search_replace(q, old, new, inject_det=None, replace_with_det=[]):\n",
        "    from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "    def join_w_offsets(t_w_o):\n",
        "        from itertools import zip_longest\n",
        "        ret = []\n",
        "        for (t1, (s1, e1)), (t2, (s2, e2)) in zip_longest(t_w_o, t_w_o[1:], fillvalue=(None, (-1, -1))):\n",
        "            ret.append(t1)\n",
        "            if e1 + 1 == s2:\n",
        "                ret.append(' ')\n",
        "\n",
        "        return \"\".join(ret)\n",
        "\n",
        "\n",
        "    def align_offset(new_start, t_w_o):\n",
        "        ret = []\n",
        "        if len(t_w_o) > 0:\n",
        "            d = new_start - t_w_o[0][1][0]\n",
        "            for t1, (s, e) in t_w_o:\n",
        "                ret.append((t1, (s + d, e + d)))\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def inject_at_index_(tokens_with_offset, word, i):\n",
        "      if i > 0:\n",
        "        one_token_before = tokens_with_offset[i-1]\n",
        "        one_word_before = one_token_before[0]\n",
        "\n",
        "        #replace\n",
        "        if one_word_before in replace_with_det:\n",
        "          gap = len(word) - len(one_word_before)\n",
        "          one_token_before_start = one_token_before[1][0]\n",
        "          det_token = (word, (one_token_before_start, one_token_before_start+len(word)))\n",
        "          tokens_with_offset[i-1] = det_token\n",
        "\n",
        "          # align\n",
        "          for j in range(i, len(tokens_with_offset)):\n",
        "            new_offset = tuple(v+gap for v in tokens_with_offset[j][1])\n",
        "            tokens_with_offset[j] = (tokens_with_offset[j][0], new_offset)\n",
        "\n",
        "\n",
        "        one_token_before = tokens_with_offset[i-1]\n",
        "        one_word_before = one_token_before[0]\n",
        "\n",
        "\n",
        "        #inject\n",
        "        if one_word_before.lower() != word:\n",
        "          one_token_before_end = one_token_before[1][1]\n",
        "          added_gap = 1+len(word)\n",
        "          det_token = (word, (one_token_before_end+1, one_token_before_end+added_gap))\n",
        "          tokens_with_offset.insert(i, det_token)\n",
        "          \n",
        "          for j in range(i+1, len(tokens_with_offset)):\n",
        "            new_offset = tuple(v+added_gap for v in tokens_with_offset[j][1])\n",
        "            tokens_with_offset[j] = (tokens_with_offset[j][0], new_offset)\n",
        "          \n",
        "          return True\n",
        "\n",
        "      return False\n",
        "\n",
        "    def search_replace_tokenized(tokens_with_offset, old_t_w_o, new_t_w_o):\n",
        "\n",
        "        old_t = [x[0] for x in old_t_w_o]\n",
        "        window_size = len(old_t)\n",
        "        for i in range(len(tokens_with_offset) - window_size + 1):\n",
        "            window_tokens = [x[0] for x in tokens_with_offset[i: i + window_size]]\n",
        "\n",
        "            if window_tokens == old_t:\n",
        "                \n",
        "                # print(tokens_with_offset)\n",
        "                if isinstance(inject_det, str):\n",
        "\n",
        "                  is_suc = inject_at_index_(tokens_with_offset, inject_det, i)\n",
        "\n",
        "                  i += int(is_suc)\n",
        "                \n",
        "                # print(tokens_with_offset)\n",
        "\n",
        "\n",
        "                bef = tokens_with_offset[:i]\n",
        "                between = tokens_with_offset[i: i+window_size]\n",
        "                rest = tokens_with_offset[i + window_size:]\n",
        "\n",
        "                start_new = between[0][1][0]\n",
        "\n",
        "                new = align_offset(start_new, new_t_w_o)\n",
        "\n",
        "                if len(new) > 0:\n",
        "                    start_rest = new[-1][1][1] + rest[0][1][0] - between[-1][1][1]\n",
        "                else:\n",
        "                    start_rest = bef[-1][1][1] + rest[0][1][0] - between[-1][1][1]\n",
        "\n",
        "                rest = align_offset(start_rest, rest)\n",
        "\n",
        "                return bef + new + rest\n",
        "\n",
        "        return None\n",
        "\n",
        "    tokens_with_offset = Whitespace().pre_tokenize_str(q)\n",
        "    old_t_w_o = Whitespace().pre_tokenize_str(old)\n",
        "    new_t_w_o = Whitespace().pre_tokenize_str(new)\n",
        "    if len(old_t_w_o) > 0:\n",
        "        new_tokens_with_offset = search_replace_tokenized(tokens_with_offset, old_t_w_o, new_t_w_o)\n",
        "\n",
        "        if new_tokens_with_offset is not None:\n",
        "            return join_w_offsets(new_tokens_with_offset)\n",
        "        else:  # failed to find\n",
        "            return None\n",
        "\n",
        "    # will return the same question if there is nothing to replace or search\n",
        "    return q"
      ],
      "metadata": {
        "id": "y6KSKgnZXqUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_replace(\"What is the color of dog running on the grass?\", \"dog\", \"cat\", inject_det='the')"
      ],
      "metadata": {
        "id": "TZqKlTls7dsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_replace(\"Who is wearing a shirt?\", \"shirt\", \"boarder\", inject_det='the', replace_with_det=['a'])"
      ],
      "metadata": {
        "id": "fFIG2BdRV9Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helpers"
      ],
      "metadata": {
        "id": "sQQcPdiTYK4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDescription:\n",
        "    def __init__(self, phrase, id, is_answer=False):\n",
        "        self.id = id\n",
        "        self.phrase = phrase\n",
        "        self.is_answer = is_answer\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.phrase\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.phrase\n",
        "\n",
        "class SemanticEqOutput:\n",
        "    def __init__(self, result: Union[bool, List[bool]], source_embeds=None, target_embeds=None, scores=None):\n",
        "        self.result = result\n",
        "        self.source_embeds = source_embeds\n",
        "        self.target_embeds = target_embeds\n",
        "        self.scores = scores\n",
        "\n",
        "    def __bool__(self):\n",
        "        return all(self.result)\n",
        "\n",
        "    def __str__(self):\n",
        "      return json.dumps({\"result\": self.result, \"scores\": self.scores})\n",
        "\n",
        "\n",
        "class DumpingStorage:\n",
        "    def __init__(self, buffer_size=3000):\n",
        "        self.buffer_size = buffer_size\n",
        "        self.storage = OrderedDict()\n",
        "        self.stabilized = 0\n",
        "\n",
        "    def __contains__(self, item):\n",
        "        return item in self.storage\n",
        "\n",
        "    def add(self, item, val):\n",
        "        self.storage.update({item: val})\n",
        "        self.stabilize()\n",
        "\n",
        "    def get(self, item):\n",
        "        return self.storage.get(item)\n",
        "\n",
        "    def stabilize(self, keep_portion=0.75):\n",
        "        if len(self.storage.keys()) > self.buffer_size:\n",
        "            pairs = list(self.storage.items())\n",
        "            unkeep = 1 - keep_portion\n",
        "            pairs = pairs[int(unkeep * len(pairs)):]  # release the most earliest\n",
        "            # pairs = random.sample(pairs, int(0.75 * len(pairs)))\n",
        "            # self.storage = {k: v for k, v in pairs}\n",
        "            self.storage = OrderedDict(pairs)\n",
        "            self.stabilized += 1"
      ],
      "metadata": {
        "id": "fkoxpvvLYdL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AugmentQuestion:\n",
        "    def __init__(self, q, failure_type, failure_reason, origin_id,image_id, generation_type, q_gec=None, gec_dist=None, is_lemmatised_aug=None,failure_sub_type=None, properties={}):\n",
        "        \"\"\"\n",
        "        q: The final question\n",
        "        failure_type: failure type between [1,5]\n",
        "        failure_reason: Describing the failure in plain language\n",
        "        q_gec: in case where grammar error correction layer has been applied, question before layer\n",
        "        gec_distance: levenshtein distance before and after GEC (grammar error correction) layer\n",
        "        is_lemmatised_aug: if lemmatization used while augmenting\n",
        "        generation_type: how the question was generated, options are: \"from_question\"/\"pre_defined\"\n",
        "        origin_id: id of the object the question created from (in case of \"from_questions\" its question id, in case of \"pre_defined\" its image id)\n",
        "        properties: additional info if needed\n",
        "        \"\"\"\n",
        "        self.q = q\n",
        "        self.q_gec = q_gec\n",
        "        self.failure_type = failure_type\n",
        "        self.failure_sub_type = failure_sub_type\n",
        "        self.failure_reason = failure_reason\n",
        "        self.gec_dist = gec_dist\n",
        "        self.is_lemmatized_aug = is_lemmatised_aug\n",
        "        self.generation_type = generation_type\n",
        "        self.origin_id = origin_id\n",
        "        self.image_id = image_id\n",
        "        self.properties = properties\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.q\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.q"
      ],
      "metadata": {
        "id": "qkYR9gV-BZiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostly, we use sentence transformers while scanning scene graphs for triplets and compare them with a given triplet\n",
        "# thus, encode of the same phrase/sentence will occur many times, instead of that we utilize memory instead of GPU/CPU usage.\n",
        "class SentenceTransformerWithMemory:\n",
        "    \"Uses RAM in order to save embeddeings in memory instead of encoding them each time\"\n",
        "\n",
        "    def __init__(self, model_name):\n",
        "        self.memory = DumpingStorage()\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def encode(self, sentences: List[str], *args, **kwargs) -> Tensor:\n",
        "\n",
        "        filtered_sentences = [sen for i, sen in enumerate(sentences) if sen not in self.memory]\n",
        "        filtered_indices = [i for i, sen in enumerate(sentences) if sen not in self.memory]\n",
        "\n",
        "        in_memory_indices = [i for i, sen in enumerate(sentences) if sen in self.memory]\n",
        "\n",
        "        if len(filtered_sentences) > 0:\n",
        "            embs = self.model.encode(filtered_sentences, *args, **kwargs)  # (len(filtered_sentences), 768)\n",
        "\n",
        "            if not isinstance(embs, Tensor):\n",
        "                embs = torch.tensor(embs)\n",
        "\n",
        "            embs_lst = embs.tolist()\n",
        "        else:\n",
        "            embs_lst = []\n",
        "\n",
        "        for s, emb in zip(filtered_sentences, embs_lst):  # update memory\n",
        "            self.memory.add(s, emb)\n",
        "\n",
        "        res = [None]*len(sentences)  # prepare output\n",
        "\n",
        "        for i, emb in zip(filtered_indices, embs_lst):  # restore it to the right index\n",
        "            res[i] = emb\n",
        "\n",
        "        for i in in_memory_indices:  # get embeddings from memory\n",
        "            s = sentences[i]\n",
        "            res[i] = self.memory.get(s)\n",
        "\n",
        "        if not all([x is not None for x in res]):\n",
        "          return self.model.encode(sentences, *args, **kwargs)\n",
        "\n",
        "        return torch.tensor(res)"
      ],
      "metadata": {
        "id": "qNjq2DzM219q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpful Maps \n",
        "(imgid->scene_graph), (subject_object -> relations), (obj -> synset)"
      ],
      "metadata": {
        "id": "uUmvu1rAZrHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mass_nouns = set([x.strip().lower() for x in open(mass_nouns_path).readlines()])"
      ],
      "metadata": {
        "id": "tmzigB14Jpia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mass_nouns.update(['floor','street', 'scene'])"
      ],
      "metadata": {
        "id": "fhfBztlfA9-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(mass_nouns)[:30]"
      ],
      "metadata": {
        "id": "s7m-KYpBKXaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(synset_mapping_path) as nf:\n",
        "  synset_mapping = json.load(nf)"
      ],
      "metadata": {
        "id": "SmKtd83mgMFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synset_mapping['man']"
      ],
      "metadata": {
        "id": "gmbpGPCeDOAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synset_mapping['people']"
      ],
      "metadata": {
        "id": "sAWJRE7-K4J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##subject_object_relation mapping - load into memory (Note: This is ~300k length hash table)\n",
        "s_o_2_relations = {}\n",
        "with open(subj_obj_2_rels_path) as f:\n",
        "    s_o_2_relations = json.load(f)"
      ],
      "metadata": {
        "id": "M3_j5BVRdNC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_o_2_relations['shoes_man']"
      ],
      "metadata": {
        "id": "aeUnyXzRdTy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_o_2_relations['building_sign']"
      ],
      "metadata": {
        "id": "seuUOYdvdhID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgid_to_scene_graph = image_id_to_scene_graph(sg_ds_path)"
      ],
      "metadata": {
        "id": "QbC61gFnKsd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(s_o_2_relations), len(imgid_to_scene_graph)"
      ],
      "metadata": {
        "id": "z78U0HTRmFUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "Orzip9nxKXg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "PUeuIhTgDNGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "WmqN3QR1TFZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U25jqe03pA9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# semantic similarity model fine tuned model (paraphrase-mpnet-base-v2)\n",
        "\n",
        "#path to fine tuned model of accommodation metric\n",
        "path_to_ft_sen_trans = ''\n",
        "\n",
        "\n",
        "\n",
        "# sen_transformer_name = 'paraphrase-mpnet-base-v2'\n",
        "sen_transformer = SentenceTransformerWithMemory(path_to_ft_sen_trans)\n",
        "\n",
        "# mnli model\n",
        "mnli_model_name = \"microsoft/deberta-base-mnli\"\n",
        "mnli_tokenizer = DebertaTokenizerFast.from_pretrained(mnli_model_name)\n",
        "mnli_model = DebertaForSequenceClassification.from_pretrained(mnli_model_name)\n",
        "\n",
        "# grammar model\n",
        "grammar_transformer_name = \"vennify/t5-base-grammar-correction\"\n",
        "happy_tt = HappyTextToText(\"T5\", grammar_transformer_name)\n",
        "\n",
        "# pos tag and dependency parser model\n",
        "mini_nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])  # improve performance\n",
        "\n",
        "# pos tag and dependency parser model\n",
        "nlp = spacy.load(\"en_core_web_trf\", disable=['parser', 'ner'])  # improve performance\n",
        "\n",
        "# object-object similarity\n",
        "glove_model = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "id": "Dg0Y_EwaKZ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Parameters"
      ],
      "metadata": {
        "id": "9_sMxWsOhmmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32"
      ],
      "metadata": {
        "id": "q54IluaShsMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Methods"
      ],
      "metadata": {
        "id": "EyX8p6kKe9jS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils Methods"
      ],
      "metadata": {
        "id": "UKW0X3Fngvvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### General utils functions"
      ],
      "metadata": {
        "id": "h-HSsEIOgn4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_same_objects_in_similar_set(similar_set, delta=10):\n",
        "  \"\"\"\n",
        "  Pre: Similar-Set length > 1\n",
        "  Object similar set is a list of objects who have the same meaning,\n",
        "  however, sometimes the annotators of VG scene graph annotate the same object multiple times.\n",
        "  In order to avoid it, we iterate the similar set and merge the same objects by the following algorithm:\n",
        "\n",
        "  while similar_set is not empty:\n",
        "  1. Pop representive from the set and put it in a cluster\n",
        "  2. For each object in the updated similar set (after pop):\n",
        "    a. if its center is delta close (window-square of +- delta) to the center of cluster, add it to the cluster\n",
        "    b. filter it from the similar set\n",
        "  3. Add respresentive of the cluster to the new similar set\n",
        "  \"\"\"\n",
        "  ss = copy.deepcopy(similar_set)\n",
        "  \n",
        "  if len(similar_set) > 1:\n",
        "    new_set = []\n",
        "\n",
        "    while len(ss) > 0:\n",
        "      rep = ss.pop(0)\n",
        "      cluster = [rep]\n",
        "\n",
        "      filter = []\n",
        "      for i, cand in enumerate(ss):\n",
        "        x = cand['x']\n",
        "        y = cand['y']\n",
        "\n",
        "        lead_x = np.average([a['x'] for a in cluster])\n",
        "        lead_y = np.average([a['y'] for a in cluster])\n",
        "        #if the center of the cluster is delta close to the compared object, add it\n",
        "        if abs(lead_x-x) <= delta and abs(lead_y-y) <= delta:\n",
        "          filter.append(i)\n",
        "          cluster.append(cand)\n",
        "      \n",
        "      ss = [o for i,o in enumerate(ss) if i not in filter]\n",
        "      new_set.append(rep) # we take the first object in the cluster, cause it doesn't matter to us\n",
        "\n",
        "    return new_set\n",
        "  else:\n",
        "    return ss"
      ],
      "metadata": {
        "id": "ZsAdnko8cQap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_set = [{'synsets': ['laptop.n.01'], 'h': 97, 'object_id': 1904014, 'names': ['laptop'], 'w': 117, 'attributes': ['pink'], 'y': 47, 'x': 266},{'synsets': ['laptop.n.01'], 'h': 97, 'object_id': 1904014, 'names': ['laptop'], 'w': 117, 'attributes': ['pink'], 'y': 40, 'x': 266},{\"synsets\": [\"laptop.n.01\"], \"h\": 97, \"object_id\": 1904014, \"names\": [\"laptop\"], \"w\": 117, \"attributes\": [\"pink\"], \"y\": 77, \"x\": 266}, {\"synsets\": [\"laptop.n.01\"], \"h\": 105, \"object_id\": 2056970, \"names\": [\"laptop\"], \"w\": 138, \"attributes\": [\"pink\"], \"y\": 73, \"x\": 266}, {\"synsets\": [\"laptop.n.01\"], \"h\": 109, \"object_id\": 2002723, \"names\": [\"laptop\"], \"w\": 119, \"y\": 75, \"x\": 268}, {'synsets': ['laptop.n.01'], 'h': 97, 'object_id': 1904014, 'names': ['laptop'], 'w': 117, 'attributes': ['pink'], 'y': 10, 'x': 20}]\n",
        "merge_same_objects_in_similar_set(sim_set)"
      ],
      "metadata": {
        "id": "Skc4fC08lfDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_mass_noun(noun):\n",
        "  global mass_nouns\n",
        "\n",
        "  if not isinstance(noun, str):\n",
        "    raise Exception(f\"{noun} argument is not string\")\n",
        "\n",
        "  return noun.lower() in mass_nouns"
      ],
      "metadata": {
        "id": "7iFbKsgqK8hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_present_progressive(rel):\n",
        "\n",
        "    # limit to only verbs\n",
        "    doc = mini_nlp(rel)\n",
        "\n",
        "    ret = []\n",
        "\n",
        "    for t in doc:\n",
        "\n",
        "      tok = t.lemma_\n",
        "      if t.pos_ == \"VERB\": # we only inflect if it is verb, skipping prepositions\n",
        "\n",
        "        pp_r_tuple = getInflection(t.lemma_, tag='VBG')\n",
        "\n",
        "        if len(pp_r_tuple) > 0:\n",
        "          tok = pp_r_tuple[0]\n",
        "\n",
        "      \n",
        "      ret.append(tok)\n",
        "\n",
        "    return \" \".join(ret)"
      ],
      "metadata": {
        "id": "guANcJUCRvX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_present_progressive('play on')"
      ],
      "metadata": {
        "id": "792UhcELsopd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectEncoder(JSONEncoder):\n",
        "  def default(self, o):\n",
        "    return o.__dict__"
      ],
      "metadata": {
        "id": "pmMd-9fn0hpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_names_from_VG_obj(obj):\n",
        "  \"\"\"Extract the names of an objects in visual genome object representation\"\"\"\n",
        "  if 'names' in obj:\n",
        "    names = obj['names']\n",
        "  elif 'name' in obj:\n",
        "    names = obj['name']\n",
        "  else:\n",
        "    names = None\n",
        "\n",
        "  if isinstance(names, str):\n",
        "    names = [names]\n",
        "\n",
        "  return names"
      ],
      "metadata": {
        "id": "R9vZXFUfA2Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_scene_graph_from_question(q_obj):\n",
        "    image_id = int(q_obj[\"imageId\"])\n",
        "    if image_id in imgid_to_scene_graph:\n",
        "        return imgid_to_scene_graph[image_id]\n",
        "    \n",
        "    return None"
      ],
      "metadata": {
        "id": "3iSCwXSJcgKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_object_id_to_string(objects, ids):\n",
        "  ret_strings = [None] * len(ids)\n",
        "  for i, id in enumerate(ids):\n",
        "    for o in objects:\n",
        "      if o[\"object_id\"] == id:\n",
        "          if \"name\" in o:\n",
        "              ret_strings[i] = o[\"name\"]\n",
        "          elif \"names\" in o and len(o[\"names\"]) > 0:\n",
        "              ret_strings[i] = o[\"names\"][0]\n",
        "              \n",
        "          break\n",
        "\n",
        "    if all([x is not None for x in ret_strings]):\n",
        "      return ret_strings"
      ],
      "metadata": {
        "id": "jgqIEbMw6i9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_object_id_to_object_obj(objects, ids):\n",
        "  ret_objects = [None] * len(ids)\n",
        "  for i, id in enumerate(ids):\n",
        "    for o in objects:\n",
        "      if o[\"object_id\"] == id:\n",
        "        ret_objects[i] = o\n",
        "        break\n",
        "    \n",
        "    if all([x is not None for x in ret_objects]):\n",
        "      return ret_objects"
      ],
      "metadata": {
        "id": "b44fMZTT5-J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks(lst, n):\n",
        "    n = max(1, n)\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "def extract_similar_words_from_batch(criterions_ans, batch):\n",
        "    sim = set()\n",
        "    for ans in criterions_ans:\n",
        "        for i, member in enumerate(ans):\n",
        "            if member: sim.add(batch[i])\n",
        "    return sim"
      ],
      "metadata": {
        "id": "0rZ7zpq2gFnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inv_map(my_map):\n",
        "  inv_map = {}\n",
        "  for k,v in my_map.items():\n",
        "    inv_map[v] = inv_map.get(v, []) + [k]\n",
        "\n",
        "  return inv_map"
      ],
      "metadata": {
        "id": "JNngx_7JgXnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_triplets_from_scene_graph(scene_graph):\n",
        "\n",
        "  relations = scene_graph[\"relationships\"]\n",
        "  objects = scene_graph[\"objects\"]\n",
        "  triplets = []\n",
        "\n",
        "  for rel_obj in relations:\n",
        "      try:\n",
        "          r_tag = str.lower(rel_obj[\"predicate\"])\n",
        "          s_tag_id = rel_obj[\"subject_id\"]\n",
        "          o_tag_id = rel_obj[\"object_id\"]\n",
        "          s_o = from_object_id_to_string(objects, [s_tag_id, o_tag_id])\n",
        "          if s_o is not None and len(s_o) == 2:\n",
        "              s, o = s_o\n",
        "              triplet = (s, r_tag, o)\n",
        "              triplets.append(triplet)\n",
        "\n",
        "      except Exception as e:\n",
        "          logger.debug(e)\n",
        "          continue\n",
        "\n",
        "  return triplets"
      ],
      "metadata": {
        "id": "5FiaPEPFtizR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_subjects_2_pair(scene_graph):\n",
        "  \"\"\"\n",
        "  Generate dict of subjects in triplets which have more than one relation:\n",
        "  e.g (dog, running on, grass), (dog, chasing, ball)\n",
        "\n",
        "  s1 -> [(r1,o1), (r2, o2),...]\n",
        "  \"\"\"\n",
        "\n",
        "  relations = scene_graph[\"relationships\"]\n",
        "  objects = scene_graph[\"objects\"]\n",
        "  d = {}\n",
        "\n",
        "  for rel_obj in relations:\n",
        "      r_str = str.lower(rel_obj[\"predicate\"])\n",
        "      s_id = rel_obj[\"subject_id\"]\n",
        "      o_id = rel_obj[\"object_id\"]\n",
        "\n",
        "      if s_id not in d:\n",
        "        d[s_id] = []\n",
        "\n",
        "      d[s_id].append((r_str, o_id)) \n",
        "\n",
        "  subj2pairs = {}\n",
        "\n",
        "  for s_id, pair_lst in d.items():\n",
        "\n",
        "    try:\n",
        "        rs = [x[0] for x in pair_lst]\n",
        "        o_ids = [s_id] + [x[1] for x in pair_lst]\n",
        "        o_strs = from_object_id_to_string(objects, o_ids)\n",
        "        if o_strs is not None and len(o_strs) == len(o_ids):\n",
        "            s = o_strs[0]\n",
        "            os = o_strs[1:]\n",
        "            subj2pairs[s] = [(r,o) for r,o in zip(rs, os)]\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.debug(e)\n",
        "        # continue\n",
        "        raise\n",
        "\n",
        "  return subj2pairs"
      ],
      "metadata": {
        "id": "cv6bgjMtod6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_triplets_from_semantic_program(q_obj):\n",
        "    \"\"\"\n",
        "    Sem_op structure: {\"operation\": string, \"dependencies\": number[], \"argument\": string\n",
        "    :param q_obj:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    def remove_id(s, reg=r\"\\((\\d+)\\)\"):\n",
        "        \"\"\"\n",
        "        Split between a string and a reference id:\n",
        "        e.g \"chair (3605777)\", \"shopping bag (xxxxx)\", \"animal,eating from,s (2323212)\"\n",
        "        :param s:\n",
        "        :param reg:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        match = re.search(reg, s)\n",
        "        p = re.compile(reg)\n",
        "        rest = p.sub('', s, 1).strip()\n",
        "        if match is not None:\n",
        "            return rest, int(match.groups()[0])\n",
        "        else:\n",
        "            return rest, -1\n",
        "\n",
        "    relations = []\n",
        "    fill = False\n",
        "    try:\n",
        "        for sem_op in reversed(q_obj[\"semantic\"]):  # reverse iterating helpful to control compositional relations\n",
        "            if fill and sem_op[\"operation\"] == \"select\" and len(relations) > 0:\n",
        "                argument = sem_op['argument']\n",
        "                obj, obj_visual_genome_id = remove_id(argument)  # \"chair (3605777)\", \"shopping bag (xxxxx)\"\n",
        "                relations[0] = tuple(\n",
        "                    [ObjectDescription(obj, obj_visual_genome_id) if x == \"FILL\" else x for x in\n",
        "                     relations[0]])  # replace\n",
        "                fill = False\n",
        "            elif sem_op[\"operation\"] == \"relate\" or sem_op[\"operation\"] == \"verify rel\":\n",
        "                argument = sem_op['argument']\n",
        "                a1, rel, a2 = argument.split(',')  # e.g \"animal,eating from,s (2323212)\"\n",
        "                subject_or_object = q_obj[\"answer\"] if a1 == \"_\" else a1  # replacing _ with answer\n",
        "                a2, obj_visual_genome_id = remove_id(a2)\n",
        "\n",
        "                fill_obj = ObjectDescription(subject_or_object, obj_visual_genome_id, a1 == \"_\")\n",
        "\n",
        "                if fill and len(relations) > 0:  # compositional\n",
        "                    relations[0] = tuple([fill_obj if x == \"FILL\" else x for x in relations[0]])  # replace\n",
        "                    fill = False\n",
        "\n",
        "                if a2 == \"s\":\n",
        "                    relations.insert(0, (fill_obj, rel, \"FILL\"))\n",
        "                    fill = True\n",
        "                elif a2 == \"o\":\n",
        "                    relations.insert(0, (\"FILL\", rel, fill_obj))\n",
        "                    fill = True\n",
        "                else:\n",
        "                    raise Exception(f\"Unknown secondary argument={a2}: {json.dumps(q_obj)}\")\n",
        "    except Exception as e:\n",
        "        # logger.debug(f\"Msg: {e}\\nFailed to extract relation on data-point : {q_obj}\")\n",
        "        return None\n",
        "\n",
        "    return relations"
      ],
      "metadata": {
        "id": "l_EnHMAJe_06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dist_over_relations(sub: str, obj: str, normalised=False) -> dict:\n",
        "    \"\"\"\n",
        "    Compute dist from pre-processed mapping: subject_object -> (r, number)[]\n",
        "    :param sub:\n",
        "    :param obj:\n",
        "    :param normalised:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    global s_o_2_relations\n",
        "    key = \"_\".join([sub, obj])\n",
        "\n",
        "    ret = dict([tuple(x) for x in (s_o_2_relations.get(key) or [])])\n",
        "\n",
        "    if normalised:\n",
        "        total = sum(ret.values())\n",
        "        ret = dict([(k, v / total) for k, v in ret.items()])\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "fQObMhwiflQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_nli(premise: Union[List[str], str], hypothesis: Union[List[str], str], auto_extend=True):\n",
        "    \"\"\"\n",
        "    Wrapper for nli classifier\n",
        "    :param premise:\n",
        "    :param hypothesis:\n",
        "    :param auto_extend:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # 0 - contradiction, 1 - neutral, 2 - entailment\n",
        "    global mnli_model\n",
        "    global mnli_tokenizer\n",
        "\n",
        "    if isinstance(premise, str):\n",
        "        premise = [premise]\n",
        "\n",
        "    if isinstance(hypothesis, str):\n",
        "        hypothesis = [hypothesis]\n",
        "\n",
        "    mnli_model.eval()\n",
        "    inputs = mnli_tokenizer(premise, hypothesis, return_tensors='pt', padding=True)\n",
        "    outputs = mnli_model(**inputs)  # (batch_size, num_labels)\n",
        "    return torch.argmax(outputs.logits, dim=-1).tolist()  # (batch_size,)"
      ],
      "metadata": {
        "id": "yt445h-XfsIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_equal(target: Union[str, List[str]], source: Union[str, List[str]], auto_extension=True):\n",
        "    if isinstance(target, str):\n",
        "        target = [target]\n",
        "    if isinstance(source, str):\n",
        "        source = [source]\n",
        "\n",
        "    if auto_extension:\n",
        "        if len(target) < len(source):\n",
        "            target = target + [target[-1]] * (len(source) - len(target))\n",
        "        elif len(source) < len(target):\n",
        "            source = source + [source[-1]] * (len(target) - len(source))\n",
        "\n",
        "    return SemanticEqOutput(result=[x == y for x, y in zip(target, source)])"
      ],
      "metadata": {
        "id": "VHp7zR4mgCVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split Object Similar Set"
      ],
      "metadata": {
        "id": "56QLTa0NLRPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_object_similar_set(similar_set):\n",
        "    \"\"\"\n",
        "    Split the given similar_set for two groups - pronouns or people/person and others\n",
        "    e.g [(girl, lying on, grass), (they, lying on, grass),(can, lying on, grass), (dog, lying on, grass), (cat, lying on, grass)]\n",
        "    interrogative = [(girl, lying on, grass), (they, lying on, grass)\u0003]\n",
        "    other = [(can, lying on, grass), (dog, lying on, grass), (cat, lying on, grass)]\n",
        "    \"\"\"\n",
        "    interrogative_synsets_names = ['person.n.01', 'homo.n.02', 'people.n.01']\n",
        "    interrogative_synsets = [wn.synset(x) for x in interrogative_synsets_names]\n",
        "    pronouns = set(['he','she','him','i','you','we','they'])\n",
        "\n",
        "    def is_pronoun(x):\n",
        "      return x.lower() in pronouns\n",
        "\n",
        "    interrogative = []\n",
        "    other = []\n",
        "    for o in similar_set:\n",
        "\n",
        "      names = set(extract_names_from_VG_obj(o))\n",
        "\n",
        "      is_inter_pronoun = any([is_pronoun(x) for x in names])\n",
        "\n",
        "      is_inter_synsets = False\n",
        "\n",
        "      if 'synsets' in o and len(o['synsets']) > 0:\n",
        "        \n",
        "        synset = wn.synset(o['synsets'][0])\n",
        "        \n",
        "        for s in interrogative_synsets:\n",
        "          common_hypernyms = synset.lowest_common_hypernyms(s)\n",
        "          if len(common_hypernyms) > 0:\n",
        "            is_inter_synsets = is_inter_synsets or synset.lowest_common_hypernyms(s)[0].name() == s.name()\n",
        "\n",
        "      if is_inter_pronoun or is_inter_synsets:\n",
        "        interrogative.append(o)\n",
        "      else:\n",
        "        other.append(o)\n",
        "\n",
        "    return interrogative, other"
      ],
      "metadata": {
        "id": "My1NBojl5Grv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgc = imgid_to_scene_graph[2377379]\n",
        "stt = from_object_id_to_object_obj(sgc['objects'], [565924, 565935])\n",
        "print(split_object_similar_set(stt))\n",
        "stt2 = [{\n",
        "  'synsets': ['water.n.01'],\n",
        "  'h': 65,\n",
        "  'object_id': 565924,\n",
        "  'names': ['water'],\n",
        "  'w': 39,\n",
        "  'attributes': ['drops', 'droplets', 'drop'],\n",
        "  'y': 144,\n",
        "  'x': 61\n",
        "  },{\n",
        "  'synsets': ['food.n.01'],\n",
        "  'h': 74,\n",
        "  'object_id': 565935,\n",
        "  'names': ['food'],\n",
        "  'w': 39,\n",
        "  'y': 132,\n",
        "  'x': 57\n",
        "  },{\n",
        "  'synsets': ['girl.n.01'],\n",
        "  'h': 74,\n",
        "  'object_id': 565935,\n",
        "  'names': ['girl'],\n",
        "  'w': 39,\n",
        "  'y': 132,\n",
        "  'x': 57},\n",
        "  {\n",
        "  'synsets': ['child.n.01'],\n",
        "  'h': 74,\n",
        "  'object_id': 565935,\n",
        "  'names': ['kid'],\n",
        "  'w': 39,\n",
        "  'y': 132,\n",
        "  'x': 57},\n",
        "  {\n",
        "  'synsets': ['man.n.01'],\n",
        "  'h': 74,\n",
        "  'object_id': 565935,\n",
        "  'names': ['man'],\n",
        "  'w': 39,\n",
        "  'y': 132,\n",
        "  'x': 57},\n",
        "  {\n",
        "  'synsets': ['man.n.01'],\n",
        "  'h': 74,\n",
        "  'object_id': 565935,\n",
        "  'names': ['man'],\n",
        "  'w': 39,\n",
        "  'y': 132,\n",
        "  'x': 57},\n",
        "  {\n",
        "  'synsets': [],\n",
        "  'h': 74,\n",
        "  'object_id': 565935,\n",
        "  'names': ['he'],\n",
        "  'w': 39,\n",
        "  'y': 132,\n",
        "  'x': 57},\n",
        "  ]\n",
        "\n",
        "pack = split_object_similar_set(stt2)\n",
        "assert len(pack[0]) == 5 and len(pack[1]) == 2\n",
        "pack"
      ],
      "metadata": {
        "id": "NZXEYiNvGBAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Similarity functions"
      ],
      "metadata": {
        "id": "nlkDaG2OgfRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_sentence_similarity_batched(s1: Union[str, List[str]], s2: Union[str, List[str]], auto_extension=True,\n",
        "                                     threshold=0.83, return_scores=False, return_embeds=False) -> SemanticEqOutput:\n",
        "    \"\"\"\n",
        "    Computing phrase similarity with Sentence BERT\n",
        "    see paper Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\n",
        "    returns a boolean vector v, where v[i] = cosine_sim(s1[i],s2[i]) > threshold.\n",
        "    :param s1:\n",
        "    :param s2:\n",
        "    :param batch_size: capping batch_size\n",
        "    :param auto_extension: If True, will extend s1 or s2 to fit dimensions for each other\n",
        "    by duplicating the last encoded sentence of the one with the smaller size, otherwise\n",
        "    will let broadcasting do the work.\n",
        "    :param threshold:\n",
        "    :return:\n",
        "\n",
        "    \"\"\"\n",
        "    # model = SentenceTransformer(model_name)\n",
        "    global sen_transformer\n",
        "    start = timer()\n",
        "    if isinstance(s1, str):\n",
        "        s1 = [s1]\n",
        "    if isinstance(s2, str):\n",
        "        s2 = [s2]\n",
        "\n",
        "    sentences = s1 + s2\n",
        "\n",
        "    bs = len(sentences)\n",
        "    sentence_embeds = sen_transformer.encode(sentences, batch_size=bs, show_progress_bar=False,\n",
        "                                             normalize_embeddings=True,\n",
        "                                             convert_to_tensor=True)  # (len(s1)+len(s2), 768)\n",
        "    sentence_embeds = torch.split(sentence_embeds, [len(s1), len(s2)])  # ((len(s1), 768), (len(s2), 768))\n",
        "    s1_embs, s2_embs = sentence_embeds\n",
        "    # this is different from broadcasting, since broadcasting is lacking 1 dimension,\n",
        "    # unlike here where the dimension size is not equal.\n",
        "    if auto_extension:\n",
        "        if len(s1) < len(s2):\n",
        "            s1_embs = s1_embs[-1, :].repeat(len(s2), 1)\n",
        "        elif len(s2) < len(s1):\n",
        "            s2_embs = s2_embs[-1, :].repeat(len(s1), 1)\n",
        "\n",
        "    similarity = torch.sum(s1_embs * s2_embs, dim=-1)  # sum over columns\n",
        "    sem_eq = (similarity > threshold).tolist()\n",
        "\n",
        "    ret = SemanticEqOutput(result=sem_eq)\n",
        "\n",
        "    if return_scores:\n",
        "        ret.scores = similarity\n",
        "\n",
        "    if return_embeds:\n",
        "        ret.source_embeds = s1_embs\n",
        "        ret.target_embeds = s2_embs\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "ULJBGOIDgD3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = bert_sentence_similarity_batched(['reins are on head', 'pane in window', 'knob on door', 'frame around window'], 'baseball cap on wall', return_scores=True)"
      ],
      "metadata": {
        "id": "M6EjEluAVnfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a.scores"
      ],
      "metadata": {
        "id": "4XoBQd89WT38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantically_equivalent(target: Union[str, List[str]], source: Union[str, List[str]], criteria=None,\n",
        "                            criteria_answers=False, **kwargs) \\\n",
        "        -> Union[SemanticEqOutput, List[SemanticEqOutput]]:\n",
        "    \"\"\"\n",
        "    Return True if target is semantically equivalent to source\n",
        "    according if exist criterion from criteria defined that is satisfied.\n",
        "    Better provide criteria suc that their computation complexity increasing. (e.g [\"eq\", \"bert\"])\n",
        "    :param criteria_answers: if True will return the result of the passed criterions as list\n",
        "    :param criteria:\n",
        "    :param target:\n",
        "    :param source:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if criteria is None:\n",
        "        criteria = ['eq']\n",
        "\n",
        "    def check_criterion(c, **kwargs):\n",
        "        if c == \"eq\":\n",
        "            return batch_equal(target, source)\n",
        "        elif c == 'bert':\n",
        "            return bert_sentence_similarity_batched(target, source, **kwargs)\n",
        "        # elif c == \"synset\":  # TODO: Adapt it to batched version\n",
        "        #     return synset_similarity(target, source, **kwargs)\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    if criteria_answers:\n",
        "        return [check_criterion(c, **kwargs) for c in criteria]\n",
        "    else:\n",
        "        res = None\n",
        "        for c in criteria:\n",
        "            res = check_criterion(c, **kwargs)\n",
        "            # if all is semantic equivalent return it to avoid checking more criteria for efficiency\n",
        "            if res:\n",
        "                return res\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "QFrU9J1XfxRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def holding_in_scene_graph_batched(scene_graph, subj: str, rel: str, obj: str, debug=True):\n",
        "    \"\"\"\n",
        "    A.K.A \"Scene Graph Validator\"\n",
        "\n",
        "    Given a triplet <subj, rel, obj> and a scene graph,\n",
        "    search the triplet within the graph according to equivalence criteria\n",
        "    return True if found else False.\n",
        "    :param scene_graph:\n",
        "    :param subj:\n",
        "    :param rel:\n",
        "    :param obj:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    def select_phrase_kind(s, r, o):\n",
        "      if subj is not None and obj is not None:\n",
        "        return f\"{s} {r} {o}\"\n",
        "      elif subj is None and obj is not None:\n",
        "        return f\"{r} {o}\"\n",
        "      elif obj is None and subj is not None:\n",
        "        return f\"{s} {r}\"\n",
        "      else:\n",
        "        return f\"{r}\"\n",
        "      \n",
        "\n",
        "\n",
        "    global batch_size\n",
        "\n",
        "    start = timer()\n",
        "\n",
        "    relations = scene_graph[\"relationships\"]\n",
        "    objects = scene_graph[\"objects\"]\n",
        "    # searching_phrase = f\"{subj} {rel} {obj}\"\n",
        "    searching_phrase = select_phrase_kind(subj, rel, obj)\n",
        "    phrase_batch = []\n",
        "\n",
        "    relations = chunks(relations, batch_size)\n",
        "\n",
        "    for batch in relations:\n",
        "        for rel_obj in batch:\n",
        "            try:\n",
        "                r_tag = str.lower(rel_obj[\"predicate\"])\n",
        "                s_tag_id = rel_obj[\"subject_id\"]\n",
        "                o_tag_id = rel_obj[\"object_id\"]\n",
        "                s_o = from_object_id_to_string(objects, [s_tag_id, o_tag_id])\n",
        "                if s_o is not None and len(s_o) == 2:\n",
        "                    s, o = s_o\n",
        "                    # found_phrase = f\"{s} {r_tag} {o}\"\n",
        "                    found_phrase = select_phrase_kind(s, r_tag, o)\n",
        "                    phrase_batch.append(found_phrase)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.debug(e)\n",
        "                continue\n",
        "\n",
        "        # demand here for \"context-based\" semantic instead of \"context-free\" equivalence of relations.\n",
        "        # print(searching_phrase)\n",
        "        phrase_criterions = semantically_equivalent(phrase_batch, searching_phrase, criteria=[\"eq\",\"bert\"],\n",
        "                                                    criteria_answers=True, **{\"return_scores\": True})\n",
        "        \n",
        "        \n",
        "        \n",
        "        # raise Exception('STOP')\n",
        "\n",
        "        criteria_results = [sem_out.result for sem_out in phrase_criterions]\n",
        "        if any([any(res) for res in criteria_results]):\n",
        "            iden_phrases = extract_similar_words_from_batch(criteria_results, phrase_batch)\n",
        "            if debug:\n",
        "              logger.debug([list(zip(sem_out.result, phrase_batch, sem_out.scores.tolist())) for sem_out in phrase_criterions if sem_out.scores is not None])\n",
        "              logger.debug(\n",
        "                  f\"Found Equally Phrases: {iden_phrases}, similar to : {searching_phrase}, Timing: {timer() - start}s\")\n",
        "            return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "m58pf-Gnf9JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_obj_holding_in_scene_graph_by_model(scene_graph, obj: str):\n",
        "    \"\"\"\n",
        "    Given an object and a scene graph,\n",
        "    search the object within the graph\n",
        "    return True if found else False.\n",
        "    :param q_obj:\n",
        "    :param subj:\n",
        "    :param rel:\n",
        "    :param obj:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    global batch_size\n",
        "\n",
        "    start = timer()\n",
        "\n",
        "    objects = scene_graph[\"objects\"]\n",
        "    objects = [x['name'] if 'name' in x else x['names'][0] for x in objects if 'name' in x or 'names' in x]\n",
        "\n",
        "    objects = chunks(objects, batch_size)\n",
        "\n",
        "    for batch in objects:\n",
        "\n",
        "        phrase_criterions = semantically_equivalent(batch, obj, criteria=[\"eq\", \"bert\"],\n",
        "                                                    criteria_answers=True)\n",
        "        criteria_results = [sem_out.result for sem_out in phrase_criterions]\n",
        "        if any([any(res) for res in criteria_results]):\n",
        "            iden_phrases = extract_similar_words_from_batch(criteria_results, batch)\n",
        "            logger.debug(\n",
        "                f\"Found Equally Phrases: {iden_phrases}, similar to : {obj}, Timing: {timer() - start}s\")\n",
        "            return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "N-yxBous5luT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_objects_similarity_word2vec(w1: str, w2:str):\n",
        "  global glove_model\n",
        "\n",
        "  # this function normalize the vectors so similarity is in [0,1]\n",
        "  return glove_model.similarity(w1,w2)"
      ],
      "metadata": {
        "id": "I36ZeTedopsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def are_synsets_equal(synset1: str, synset2: str, threshold=0.5):\n",
        "  if synset1 == synset2:\n",
        "    return True\n",
        "\n",
        "  s1 = wn.synset(synset1)\n",
        "  s2 = wn.synset(synset2)\n",
        "\n",
        "  s1_names = s1.lemma_names()\n",
        "  s2_names = s2.lemma_names()\n",
        "\n",
        "  intersection = set(s1_names).intersection(s2_names)\n",
        "\n",
        "  if len(intersection) > 0:\n",
        "    return True\n",
        "\n",
        "\n",
        "  try:\n",
        "    if len(s1_names) > 0 and len(s2_names) > 0:\n",
        "      #representive\n",
        "\n",
        "      sim = compute_objects_similarity_word2vec(s1_names[0], s2_names[0])\n",
        "      # logger.debug(f\"{s1_names[0]}-{s2_names[0]}: {sim}\")\n",
        "\n",
        "      if sim >= threshold:\n",
        "        return True\n",
        "\n",
        "\n",
        "      # combs = list(product(s1_names, s2_names))\n",
        "\n",
        "      # sims = [(comb, compute_objects_similarity_word2vec(*comb)) for comb in combs]\n",
        "\n",
        "      # for comb, sim in sims:\n",
        "      #   logger.debug(f\"{comb[0]}-{comb[1]}: {sim}\")\n",
        "\n",
        "      # if any([x[1] >= threshold for x in sims]):\n",
        "      #   return True\n",
        "\n",
        "  except KeyError as e:\n",
        "    # logger.debug(e)\n",
        "    pass\n",
        "\n",
        "\n",
        "  return False"
      ],
      "metadata": {
        "id": "8APeaVh8u5EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "are_synsets_equal('laptop.n.01', 'bag.n.01')"
      ],
      "metadata": {
        "id": "0gKq7qG971hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "are_synsets_equal('car.n.01', 'vehicle.n.01')"
      ],
      "metadata": {
        "id": "N8_58b3e8g4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "are_synsets_equal('computer.n.01', 'laptop.n.01')"
      ],
      "metadata": {
        "id": "VTfQIH6b8-rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_obj_holding_in_scene_graph_by_synsets(scene_graph, obj: str, obj_synset: str):\n",
        "    \"\"\"\n",
        "    Given an object and a scene graph,\n",
        "    search the object within the graph\n",
        "    return True if found else False.\n",
        "    :param q_obj:\n",
        "    :param subj:\n",
        "    :param rel:\n",
        "    :param obj:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    global synset_mapping\n",
        "\n",
        "    # check out \"are_two_objects_similar\" for similarity definition\n",
        "\n",
        "    objects = scene_graph[\"objects\"]\n",
        "\n",
        "    for obj_dict in objects:\n",
        "      \n",
        "      synsets = obj_dict['synsets'] if 'synsets' in obj_dict else None\n",
        "\n",
        "      #if synsets are available we compare them\n",
        "      if synsets is not None and len(synsets) > 0 and obj_synset is not None:\n",
        "        cur_synset = synsets[0] # we take only the first cause it is usually the region main intention\n",
        "\n",
        "        if are_synsets_equal(cur_synset, obj_synset):\n",
        "          return True\n",
        "\n",
        "\n",
        "        # if obj_synset in synsets:\n",
        "        #   return True\n",
        "\n",
        "      #if names are available we compare them\n",
        "      # names = extract_names_from_VG_obj(obj_dict)\n",
        "      \n",
        "      # if names is not None:\n",
        "      #   if obj in names:\n",
        "      #     return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "NYFFG1BJhDmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sg_check = imgid_to_scene_graph[2377378]\n",
        "sg_check"
      ],
      "metadata": {
        "id": "sOIYEnIuxGDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_obj_holding_in_scene_graph_by_synsets(sg_check, 'laptop', 'laptop.n.01')"
      ],
      "metadata": {
        "id": "aw5nJTmgMRFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similar_sets_by_predicate(elements, predicate):\n",
        "  \"\"\"\n",
        "  General algorithm to compute similar sets between elements\n",
        "  (will group up elements which hold on predicate)\n",
        "  predicate signature (ele1, ele2), where ele_i is from elements\n",
        "  \"\"\"\n",
        "\n",
        "  #we assign each element to its own similar set\n",
        "  enum_elements2similar_sets = dict([(i,i) for i, x in enumerate(elements)])\n",
        "\n",
        "  combs = list(combinations(range(len(elements)), 2))\n",
        "\n",
        "  #for every combination we compute if it is similar\n",
        "  for i1,i2 in combs:\n",
        "\n",
        "    e1 = elements[i1]\n",
        "    e2 = elements[i2]\n",
        "    \n",
        "    is_similar = predicate(e1, e2)\n",
        "\n",
        "    if is_similar:\n",
        "      \n",
        "      #lowest index is the representive\n",
        "      low, big = sorted([i1,i2])\n",
        "\n",
        "      #merging synsets\n",
        "      for element_num, similar_set_index in enum_elements2similar_sets.items():\n",
        "        if similar_set_index == big:\n",
        "          enum_elements2similar_sets[element_num] = low\n",
        "\n",
        "  similar_sets2elements = inv_map(enum_elements2similar_sets) #inverse\n",
        "\n",
        "  #set indices\n",
        "  sets_indices = list(similar_sets2elements.values())\n",
        "\n",
        "  similar_sets = [[elements[i] for i in indices] for indices in sets_indices]\n",
        "\n",
        "  return similar_sets"
      ],
      "metadata": {
        "id": "XKlHGdfj5gu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_similar_sets_by_predicate(['a','b','a','b','c'], lambda x,y: x==y)"
      ],
      "metadata": {
        "id": "4pNwDG9scoTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def are_two_objects_similar(o1, o2):\n",
        "  syn1 = o1['synsets'][0]\n",
        "  syn2 = o2['synsets'][0]\n",
        "\n",
        "  return are_synsets_equal(syn1, syn2)\n",
        "\n",
        "\n",
        "  # is_similar = (syn1 == syn2)\n",
        "\n",
        "  # names1 = extract_names_from_VG_obj(o1)\n",
        "  # names2 = extract_names_from_VG_obj(o2)\n",
        "\n",
        "  # if names1 and names2:\n",
        "  #   names1 = set(names1)\n",
        "  #   names2 = set(names2)\n",
        "  #   is_similar = is_similar or (len(names1.intersection(names2)) > 0)\n",
        "\n",
        "  # return is_similar"
      ],
      "metadata": {
        "id": "q8XgvQBbg9Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def are_objects_comparable(o1, o2):\n",
        "  return ('synsets' in o1 and 'synsets' in o2) and len(o1['synsets']) > 0 and len(o2['synsets']) > 0"
      ],
      "metadata": {
        "id": "-4KxSpud-BUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_object_similar_groups(scene_graph):\n",
        "    \"\"\"\n",
        "    Outputs list of lists of objects, where two similar objects (similarity defined with predicate)\n",
        "    will end up in the same group.\n",
        "    example of object from scene graph:\n",
        "    {\n",
        "      \"synsets\":[\"apple.n.01\"],\n",
        "      \"h\":119,\"object_id\":1023988,\n",
        "      \"names\":[\"apple\"],\n",
        "      \"w\":126,\n",
        "      \"attributes\":[\"shiny\",\"fresh\",\"whole\",\"uneaten\",\"fruit\",\"red\",\"unpeeled\"],\n",
        "      \"y\":233,\"x\":339}\n",
        "    There are few cases which we need to pay attention to:\n",
        "    1. synsets contain multiple different synsets, but names contain only 1\n",
        "    2. synsets contain multiple different synsets and there are few names\n",
        "    3. synsets contain 1 synset but names contain multiple options\n",
        "    4. synset contain 1 synset and names contain 1 name - OPTIMAL\n",
        "\n",
        "    we filter options 1 and 2, since if there are multiple synsets it means there are different meanings\n",
        "    for the same object and then it become ambigious to decide which one we need to choose for comparison.\n",
        "\n",
        "    we define similar group:\n",
        "\n",
        "    if synset is equal or len(names intersection) > 0\n",
        "\n",
        "    :param q_obj:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    objects = scene_graph[\"objects\"]\n",
        "    objects = [x for x in objects if 'synsets' in x and len(x['synsets']) == 1]\n",
        "\n",
        "\n",
        "    return compute_similar_sets_by_predicate(objects, are_two_objects_similar)"
      ],
      "metadata": {
        "id": "EJjaWB4Q5aAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_triplet_similar_groups(scene_graph):\n",
        "  \"\"\"\n",
        "  This function computes similarity groups for triplets \n",
        "  i.e group triplets under the same list, where\n",
        "  1. triplets in group have the same relation and the same subject\n",
        "  2. triplets in group have the same relation and the same object\n",
        "  \"\"\"\n",
        "\n",
        "  relationships = scene_graph[\"relationships\"]\n",
        "\n",
        "  def subj_predicate(r1_obj, r2_obj):\n",
        "    r1 = str(r1_obj['predicate']).lower()\n",
        "    r2 = str(r2_obj['predicate']).lower()\n",
        "\n",
        "    s1_id = r1_obj['subject_id']\n",
        "    s2_id = r2_obj['subject_id']\n",
        "\n",
        "    return r1 == r2 and s1_id == s2_id\n",
        "\n",
        "  def obj_predicate(r1_obj, r2_obj):\n",
        "    r1 = str(r1_obj['predicate']).lower()\n",
        "    r2 = str(r2_obj['predicate']).lower()\n",
        "\n",
        "    o1_id = r1_obj['object_id']\n",
        "    o2_id = r2_obj['object_id']\n",
        "\n",
        "    return r1 == r2 and o1_id == o2_id\n",
        "\n",
        "  return compute_similar_sets_by_predicate(relationships, subj_predicate), compute_similar_sets_by_predicate(relationships, obj_predicate)"
      ],
      "metadata": {
        "id": "k6lKRlIL4ZF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_plausible_pair(n1, n2):\n",
        "  \"\"\"Checks is noun1 and noun2 are plausible pair in Visual Genome - that is if they are embedded\n",
        "   under some relation, e.g n1=dog, n2=grass, check if dog_grass has some relation to embedded under, could be running_on for example\"\"\"\n",
        "  key = f\"{n1}_{n2}\"\n",
        "  return key in s_o_2_relations"
      ],
      "metadata": {
        "id": "etjZvTDE4yH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Augementation through lemmatization and grammar error correction layer"
      ],
      "metadata": {
        "id": "ruRBuyx_hjnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_grammar(s):\n",
        "    \"\"\"Taken from HuggingFace model name: vennify/t5-base-grammar-correction\"\"\"\n",
        "    global happy_tt\n",
        "    args = TTSettings(num_beams=5, min_length=1)\n",
        "    result = happy_tt.generate_text(f\"grammar: {s}\", args=args)\n",
        "    return [result.text, lev_dis(s, result.text)] # new_text, levenstein distance from old"
      ],
      "metadata": {
        "id": "jD4-rT3Nj4Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to check if the augmentation was used via lemmatization, check aug stats before and after\n",
        "\n",
        "def augment(q_obj, exist_phrase, aug_phrase, augment_stats=None, inject_det=None, replace_with_det=[]):\n",
        "    \"\"\"\n",
        "    Phrase can be with multiple words, we need to find each of them sequentially in order to properly augment.\n",
        "    Descriptive verbs and prepositional phrases can be in a canonic form\n",
        "    or with different suffixes of past/future/plural\n",
        "    :param q_obj:\n",
        "    :param exist_phrase: the phrase within the question to search for\n",
        "    :param aug_phrase: the phrase to replace with\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    q_str = q_obj[\"question\"]\n",
        "\n",
        "    q_a1 = search_replace(q_str, exist_phrase, aug_phrase, inject_det=inject_det, replace_with_det=replace_with_det)\n",
        "\n",
        "    if q_a1 is not None:  # non lemma\n",
        "        # q_new, q_fixed = complete(q_obj, q_a1)\n",
        "        logger.debug(f\"Successfully augmented from: {q_str} --> {q_a1}\")\n",
        "        if augment_stats:\n",
        "            augment_stats[\"original\"] += 1\n",
        "        return q_a1, True\n",
        "\n",
        "    else:  # lemmatisation of the question\n",
        "        q_lemma = \" \".join([x.lemma_ for x in nlp(q_str)])\n",
        "        exist_phrase_lemma = \" \".join([x.lemma_ for x in nlp(exist_phrase)])\n",
        "        q_a2 = search_replace(q_lemma, exist_phrase_lemma, aug_phrase)\n",
        "\n",
        "        if q_a2 is not None:\n",
        "            # q_new, q_fixed = complete(q_obj, q_a2, lemmatized_aug=True)\n",
        "            logger.debug(f\"Successfully (Through Lemma) augmented from: {q_str} --> {q_a2}\")\n",
        "            if augment_stats:\n",
        "                augment_stats[\"lemma\"] += 1\n",
        "            return q_a2, True\n",
        "        else:\n",
        "            logger.debug(\n",
        "                f\"Could not augment: q: {q_obj} \\n Found Phrase: [{exist_phrase}] which is not correctly formed within:\\n {q_str}, \")\n",
        "            if augment_stats:\n",
        "                augment_stats[\"failed\"] += 1\n",
        "            return q_obj, False"
      ],
      "metadata": {
        "id": "TDGOnZblhiS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting Relations Methods"
      ],
      "metadata": {
        "id": "BgtaKAVOgkiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_most_freq_rand_selection(id, scene_graph, subj: str, rel: str, obj: str, trials=20, top=5):\n",
        "\n",
        "    from_top = top\n",
        "    freq_dist = compute_dist_over_relations(subj, obj, normalised=True)\n",
        "    freq_dist = sorted(freq_dist.items(), key=lambda x: x[1], reverse=True)\n",
        "    if len(freq_dist) > 0:\n",
        "        total_trials = 0\n",
        "        while total_trials < trials:\n",
        "            if total_trials > 0 and total_trials % top == 0:  # each top cycle we increase the possibilities to sample from\n",
        "                from_top += top\n",
        "            chosen_index = np.random.randint(0, min(len(freq_dist), from_top))\n",
        "            aug_rel, prob = freq_dist[chosen_index]\n",
        "            orig_phrase = f\"{subj} {rel} {obj}\"\n",
        "            aug_pharse = f\"{subj} {aug_rel} {obj}\"\n",
        "            if not semantically_equivalent(aug_rel, rel, criteria=['eq', 'bert']) and not semantically_equivalent(\n",
        "                    aug_pharse, orig_phrase, criteria=['eq', 'bert']) and not check_timing(holding_in_scene_graph_batched, sg_ds_path,scene_graph, subj,aug_rel, obj):\n",
        "                return freq_dist[chosen_index]  # exit-point\n",
        "            total_trials += 1\n",
        "\n",
        "        logger.debug(f\"Process of choosing relations failed for data point id: {id}\")\n",
        "        logger.debug(f\"Freq dist: {json.dumps(freq_dist)}\")\n",
        "    else:\n",
        "        logger.debug(f\"Empty Freq dist\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "kYsyIkAYgjsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_by_entailment(id, scene_graph, subj: str, rel: str, obj: str, random_candidates=True):\n",
        "    \"\"\"\n",
        "    Choose a relation by utilizing NLI classifier, predicting each relation candidate such that:\n",
        "    premise = relation presupposition, hypothesis = candidate presupposition.\n",
        "    Filter any entailed presuppositions and return the first candidate which\n",
        "    is not semantic similar to the premise and not found in the scene graph.\n",
        "    :param id:\n",
        "    :param q_obj:\n",
        "    :param subj:\n",
        "    :param rel:\n",
        "    :param obj:\n",
        "    :param threshold:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    freq_dist = compute_dist_over_relations(subj, obj, normalised=True)\n",
        "\n",
        "    if len(freq_dist) > 0:\n",
        "        rels = list(freq_dist.keys())\n",
        "        presupp_cands = [f\"{subj} {r} {obj}\" for r in rels]\n",
        "        presupp = f\"{subj} {rel} {obj}\"\n",
        "\n",
        "        nli_labels = classify_nli([presupp] * len(presupp_cands), presupp_cands)  # size=len(cands)\n",
        "        cands = [(x, nli_labels[i]) for i, x in enumerate(presupp_cands) if\n",
        "                 nli_labels[i] in [0, 1]]  # allow contradiction and neutral\n",
        "\n",
        "        sem_eq_input = [x[0] for x in cands]  # take only presuppositions\n",
        "        if len(sem_eq_input) > 0:\n",
        "            output = semantically_equivalent([presupp], sem_eq_input, criteria=['eq', 'bert'],\n",
        "                                             **{\"return_scores\": True})\n",
        "            if not output:  # not all semantic equivalent (= exist a member which is semantic equivalent)\n",
        "                sim_scores = output.scores.tolist()\n",
        "                # to avoid any neutral which can be understood through accommodation\n",
        "                is_eq = output.result\n",
        "                cands = [[*x, sim_scores[i]] for i, x in enumerate(cands) if not is_eq[i]]\n",
        "\n",
        "                # select according to the dist created by soft-max on all candidate scores\n",
        "                # the higher your score the more chance you will get selected.\n",
        "                # or just select randomly\n",
        "\n",
        "                p = None if random_candidates else softmax([x[-1] for x in cands])\n",
        "                \n",
        "                for i in np.random.choice(len(cands), len(cands), p=p, replace=False):\n",
        "                    cand, nli_label, score = cands[i]\n",
        "                    split = cand.split()\n",
        "                    r = \" \".join(split[1:-1])\n",
        "                    if not holding_in_scene_graph_batched(scene_graph, subj, r, obj):\n",
        "                        return r, nli_label, score\n",
        "\n",
        "                logger.debug(f\"Process of choosing relations failed for data point id: {id}\")\n",
        "                logger.debug(f\"Freq dist: {json.dumps(list(freq_dist.keys()))}\")\n",
        "            else:\n",
        "                logger.debug(f\"There is a triplet in which is semantic equivalent to: {presupp}\")\n",
        "                logger.debug(\n",
        "                    f\"Presupp: {presupp}, Cands: {[[*x, output.scores.tolist()[i]] for i, x in enumerate(cands) if output.scores is not None]}\")\n",
        "        else:\n",
        "            logger.debug(f\"Presupp: {presupp}, All cands: {presupp_cands} classified as entailed.\")\n",
        "    else:\n",
        "        logger.debug(f\"Empty Freq dist for subj={subj}, obj={obj}\")"
      ],
      "metadata": {
        "id": "zuqQsaoEfZri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_relation(method: str, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Factory method to bridge choosing strategy\n",
        "    :param method:\n",
        "    :param args:\n",
        "    :param kwargs:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if method == \"k_most_freq_rand_selection\":\n",
        "        return k_most_freq_rand_selection(*args, **kwargs)\n",
        "    elif method == \"entailment\":\n",
        "        return choose_by_entailment(*args, **kwargs)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "dT3osKtMfT3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating questions"
      ],
      "metadata": {
        "id": "TNsVRKEC1SAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating Maps"
      ],
      "metadata": {
        "id": "dzF6sgtdLbXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r_s_or_o_2_relations(s_o_2_relations):\n",
        "  \"\"\"\n",
        "  generate two maps from the extracted \"subject_object -> relations\" occurance map:\n",
        "  1. relation_object -> subjects\n",
        "  2. subject_relation -> objects\n",
        "  \"\"\"\n",
        "  r_o_2_subjects = {}\n",
        "  s_r_2_objects = {}\n",
        "\n",
        "  for s_o, relations_occs in s_o_2_relations.items():\n",
        "    # \"shade_sidewalk\": [[\"on\", 1], [\"on top of\", 1]]\n",
        "    rels = set([x[0] for x in relations_occs])\n",
        "\n",
        "    subj, obj = s_o.split('_')\n",
        "\n",
        "    for rel in rels:\n",
        "      key = f\"{rel}_{obj}\"\n",
        "\n",
        "      if key not in r_o_2_subjects:\n",
        "        r_o_2_subjects[key] = set()\n",
        "\n",
        "      r_o_2_subjects[key].add(subj)\n",
        "\n",
        "      key = f\"{subj}_{rel}\"\n",
        "\n",
        "      if key not in s_r_2_objects:\n",
        "        s_r_2_objects[key] = set()\n",
        "\n",
        "      s_r_2_objects[key].add(obj)\n",
        "\n",
        "  return {k:list(v) for k,v in r_o_2_subjects.items()}, {k:list(v) for k,v in s_r_2_objects.items()}"
      ],
      "metadata": {
        "id": "e6n6wGyw5hf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will populate helpful maps:\n",
        "1. relation_object => subjects = [s1,s2,s3,..]\n",
        "2. subject_relation => objects = [o1,o2,o3,...]\n",
        "\n",
        "Additionally, their keys as lists (used for sampling):\n",
        "\n",
        "r_o = list of 1st map keys\n",
        "s_r = list of 2nd map keys"
      ],
      "metadata": {
        "id": "lU8RlwNY4Zap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_o_2_subjects, s_r_2_objects = r_s_or_o_2_relations(s_o_2_relations)\n",
        "s_r = list(s_r_2_objects.keys())\n",
        "r_o = list(r_o_2_subjects.keys())"
      ],
      "metadata": {
        "id": "TQHiGFDZAMvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(s_r), len(r_o)"
      ],
      "metadata": {
        "id": "l5PuL0o3mzpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def check_shuffle_timing():\n",
        "#   start = timer()\n",
        "#   np.random.shuffle(s_r) # in-place, O(n)\n",
        "#   print(f\"timing: {timer() - start}\")\n",
        "\n",
        "# check_shuffle_timing()"
      ],
      "metadata": {
        "id": "n7mMeZw1mpQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_plausible_relation_for_object(obj: str):\n",
        "  np.random.shuffle(r_o)\n",
        "  for pair in r_o:\n",
        "    r, o = pair.split('_')\n",
        "    if o == obj:\n",
        "      return r\n",
        "\n",
        "  return None\n",
        "\n",
        "def search_plausible_relation_for_subject(obj: str):\n",
        "  np.random.shuffle(s_r)\n",
        "  for pair in s_r:\n",
        "    s, r = pair.split('_')\n",
        "    if s == obj:\n",
        "      return r\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "7SezOgGXAJ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_relations_for_object(obj: str):\n",
        "  global r_o\n",
        "  rels = []\n",
        "  for pair in r_o:\n",
        "    r, o = pair.split('_')\n",
        "    if o == obj:\n",
        "      rels.append(r)\n",
        "\n",
        "  return rels\n",
        "\n",
        "\n",
        "def collect_relations_for_subject(subj: str):\n",
        "  global s_r\n",
        "  rels = []\n",
        "  for pair in s_r:\n",
        "    s, r = pair.split('_')\n",
        "    if s == subj:\n",
        "      rels.append(r)\n",
        "\n",
        "  return rels\n"
      ],
      "metadata": {
        "id": "QmUYr_y3CvR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sampling Methods"
      ],
      "metadata": {
        "id": "H5WNGujYLe1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_embedded_relation_randomly(scene_graph, subj: str, obj: str):\n",
        "    \"\"\"\n",
        "    Given subject and object, sample a relation embedded between them\n",
        "    from plausible relations of VG  and validate the triplet isn't holding in scene graph.\n",
        "    :param subj:\n",
        "    :param rel:\n",
        "    :param obj:\n",
        "    :param threshold:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    freq_dist = compute_dist_over_relations(subj, obj, normalised=True)\n",
        "\n",
        "    if len(freq_dist) > 0:\n",
        "        rels = list(freq_dist.keys())\n",
        "        np.random.shuffle(rels) # we choose randomly\n",
        "\n",
        "        for rel in rels:\n",
        "           if not holding_in_scene_graph_batched(scene_graph, subj, rel, obj, debug=False):\n",
        "                  return rel\n",
        "\n",
        "        logger.debug(f\"Process of sample_embedded_relation_randomly failed for subj={subj}, obj={obj}\")\n",
        "    else:\n",
        "        logger.debug(f\"Empty Freq dist for subj={subj}, obj={obj}\")\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "8V96NDNzfJ2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_noun_and_validate_triplets(scene_graph, triplet, subj=True):\n",
        "  \"\"\"\n",
        "  Sampling a subject or object (with subj=True as switch) from visual genome distribution\n",
        "  and validating if the triplet exists in the scene graph\n",
        "\n",
        "  None will return if key not in map or didnt find candidate that not holding in scene graph.\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  subj, rel, obj = triplet\n",
        "\n",
        "  def validate_presupp_failure(cand):\n",
        "    \"returns if candidate (subj or obj) is not holding in scene graph (i.e will trigger failure)\"\n",
        "    return subj and not holding_in_scene_graph_batched(scene_graph, cand, rel, obj) \\\n",
        "      or (not subj and not holding_in_scene_graph_batched(scene_graph, subj, rel, cand))\n",
        "\n",
        "\n",
        "  map = r_o_2_subjects if subj else s_r_2_objects\n",
        "\n",
        "  key = f\"{rel}_{obj}\" if subj else f\"{subj}_{rel}\"\n",
        "\n",
        "  if key in map:\n",
        "    # sample valid subject or object\n",
        "    cands = copy.deepcopy(map[key])\n",
        "    np.random.shuffle(cands)\n",
        "    for cand in cands:\n",
        "\n",
        "      if validate_presupp_failure(cand):\n",
        "        return cand\n",
        "\n",
        "  return None\n"
      ],
      "metadata": {
        "id": "AYG0T75O14_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_plausible_pair(scene_graph, subj=True):\n",
        "  \"\"\"\n",
        "  This method samples plausible pair (subj or obj) and relation from all visual genome pairs\n",
        "  which has idenfied synset to compare with.\n",
        "  i.e noun that appeared in some relationship in visual genome\n",
        "  and validate it doesn't hold in scene graph\n",
        "  \"\"\"\n",
        "  global synset_mapping\n",
        "\n",
        "  def validate_noun_failure(noun, noun_synset):\n",
        "    return not is_obj_holding_in_scene_graph_by_synsets(scene_graph, noun, noun_synset)\n",
        "\n",
        "  pairs_str = s_r if subj else r_o\n",
        "\n",
        "  np.random.shuffle(pairs_str) # in-place, O(n)\n",
        "\n",
        "  for pair in pairs_str:\n",
        "    if subj:\n",
        "      noun, rel = pair.split('_')\n",
        "    else:\n",
        "      rel, noun = pair.split('_')\n",
        "\n",
        "    noun_synset = synset_mapping[noun] if noun in synset_mapping else None\n",
        "    \n",
        "    if noun_synset is not None and validate_noun_failure(noun, noun_synset):\n",
        "      return pair\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "hyPbV6g-G9bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_plausible_pair_from_scene_graph(scene_graph):\n",
        "  \"\"\"\n",
        "  This method samples plausible pair (subj or obj) and relation from the scene graph,\n",
        "  then it validates it is not in the scene graph.\n",
        "\n",
        "  e.g \n",
        "  (s,r,o) => (s,r') => check over scene-graph (s,r') ~! (s,r'')\n",
        "  (s,r,o) => (r', o) => check over scene-graph (r', o) ~! (r'', o)\n",
        "  \"\"\"\n",
        "  global synset_mapping\n",
        "\n",
        "  def validate_pair_failure(s, r, o):\n",
        "    return not holding_in_scene_graph_batched(scene_graph, s, r, o)\n",
        "\n",
        "  scene_graph_triplets = extract_triplets_from_scene_graph(scene_graph)\n",
        "\n",
        "  subj_pair = None\n",
        "  obj_pair = None\n",
        "\n",
        "  for t in scene_graph_triplets:\n",
        "    s, r, o = t\n",
        "\n",
        "    #subj\n",
        "    if subj_pair is None:\n",
        "      rel_lst = collect_relations_for_subject(s)\n",
        "      for r in rel_lst:\n",
        "        if validate_pair_failure(s, r, None):\n",
        "          subj_pair = (s, r)\n",
        "          break\n",
        "\n",
        "    #obj\n",
        "    if obj_pair is None:\n",
        "      rel_lst = collect_relations_for_object(o)\n",
        "      for r in rel_lst:\n",
        "        if validate_pair_failure(None, r, o):\n",
        "          obj_pair = (r, o)\n",
        "          break\n",
        "\n",
        "    \n",
        "    if subj_pair is not None and obj_pair is not None:\n",
        "      break\n",
        "\n",
        "\n",
        "  return subj_pair, obj_pair"
      ],
      "metadata": {
        "id": "QKrrEwxM_6_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types generation"
      ],
      "metadata": {
        "id": "i-IwqxX5LiGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Type 1\n",
        "Definitive reference to a non-existent object failure.\n",
        "\n",
        "From question:\n",
        "\n",
        "1. (man, to the left of, pedestrians)\n",
        "  \"What is the man to the left of the pedestrians wearing?\" \n",
        "  -> (woman, to the left of, pedestrians)\n",
        "  \"What is the woman to the left of the pedestrians wearing?\"\n",
        "\n",
        "Pre-Defined:\n",
        "\n",
        "\n",
        "1. Who is [REL] the [OBJ]? - (Who is wearing the jacket?) -> \n",
        "\n",
        "  We sample with with respect to two conditions:\n",
        "\n",
        "  [VALIDITY]: from the plausible relationships (in VG) sample wearing_o. \n",
        "\n",
        "  [FAILURE]: check if o in scene graph.                          \n",
        "\n",
        "  **Warning**: if we check if anything is wearing an object in the scene graph and the object does exist in the scene, then the type of failure changes to nothing is wearing an object instead of non-existent object.\n",
        "\n",
        "2. What is the [SUBJ] [REL]? - (What is the man throwing?) ->\n",
        "\n",
        "  [VALIDITY]: from the plausible relationships (in VG) sample s_wearing. \n",
        "  [FAILURE]: check if s in scene graph.\n",
        "\n",
        "\n",
        "3. Where is the [SUBJ/OBJ]? - sample object that doesnt hold in scene graph (Where is the jacket?)"
      ],
      "metadata": {
        "id": "-gXm9n0hkhfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_1_from_questions(q_obj, id, triplet, aug_stats, subj_has_multiple_presuppositions=False):\n",
        "\n",
        "  from_questions = []\n",
        "\n",
        "  #from question\n",
        "\n",
        "  scene_graph = extract_scene_graph_from_question(q_obj)\n",
        "\n",
        "  if scene_graph:\n",
        "\n",
        "    #subj\n",
        "    if not subj_has_multiple_presuppositions:\n",
        "      cand = sample_noun_and_validate_triplets(scene_graph, triplet, subj=True)\n",
        "\n",
        "      if cand is not None:\n",
        "        s,r,o = triplet\n",
        "        exist_phrase = s\n",
        "\n",
        "        lemmas_before = aug_stats['lemma']\n",
        "        q_new, is_suc = augment(q_obj,exist_phrase, cand, aug_stats, inject_det=\"the\", replace_with_det=['a'])\n",
        "\n",
        "        if is_suc:\n",
        "          q_new_gec, lev_dist = fix_grammar(q_new)\n",
        "\n",
        "          q = AugmentQuestion(\n",
        "              q=q_new_gec,\n",
        "              failure_type=1,\n",
        "              failure_reason=f\"No {cand} in image\",\n",
        "              origin_id=id,\n",
        "              image_id=q_obj['imageId'],\n",
        "              generation_type=\"from_questions\",\n",
        "              q_gec=q_new,\n",
        "              gec_dist=lev_dist,\n",
        "              is_lemmatised_aug=(aug_stats['lemma'] - lemmas_before == 1),\n",
        "              properties={\"is_subj_aug\":True, \"triplet_sampled\": (cand, r, o)}\n",
        "          )\n",
        "\n",
        "          from_questions.append(q)\n",
        "\n",
        "    #obj\n",
        "    cand = sample_noun_and_validate_triplets(scene_graph, triplet, subj=False)\n",
        "\n",
        "    if cand is not None:\n",
        "      s,r,o = triplet\n",
        "      exist_phrase = o\n",
        "\n",
        "      lemmas_before = aug_stats['lemma']\n",
        "      q_new, is_suc = augment(q_obj,exist_phrase, cand, aug_stats, inject_det=\"the\", replace_with_det=['a'])\n",
        "\n",
        "      if is_suc:\n",
        "        q_new_gec, lev_dist = fix_grammar(q_new)\n",
        "\n",
        "        q = AugmentQuestion(\n",
        "            q=q_new_gec,\n",
        "            failure_type=1,\n",
        "            failure_reason=f\"No {cand} in image\",\n",
        "            origin_id=id,\n",
        "            image_id=q_obj['imageId'],\n",
        "            generation_type=\"from_questions\",\n",
        "            q_gec=q_new,\n",
        "            gec_dist=lev_dist,\n",
        "            is_lemmatised_aug=(aug_stats['lemma'] - lemmas_before == 1),\n",
        "            properties={\"is_subj_aug\":False, \"triplet_sampled\": (s, r, cand)}\n",
        "        )\n",
        "\n",
        "        from_questions.append(q)\n",
        "\n",
        "  return from_questions\n",
        "  \n"
      ],
      "metadata": {
        "id": "KG1maLhXtVK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_1_pre_defined(scene_graph):\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  global synset_mapping\n",
        "\n",
        "  pre_defined = []\n",
        "\n",
        "  id = scene_graph[\"image_id\"]\n",
        "\n",
        "  #pre-defined 1\n",
        "  pair_str = sample_plausible_pair(scene_graph, subj=False)\n",
        "  if pair_str:\n",
        "    r, o = pair_str.split('_')\n",
        "\n",
        "    #we know it has synset since it is pre-condition for \"sample_plausible_pair\"\n",
        "    noun_synset = synset_mapping[o]\n",
        "\n",
        "    pp_r = transform_present_progressive(r)\n",
        "\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Who is {pp_r} the {o}?\",\n",
        "        failure_type=1,\n",
        "        failure_sub_type=1,\n",
        "        failure_reason=f\"No {o} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\":False, \"pair_sampled\": (r, o), \"noun_synset\": noun_synset}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "    #pre-defined 3\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Where is the {o}?\",\n",
        "        failure_type=1,\n",
        "        failure_sub_type=3,\n",
        "        failure_reason=f\"No {o} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\":False, \"noun_sampled\": o, \"noun_synset\": noun_synset}\n",
        "    )\n",
        "\n",
        "    pre_defined.append(q)\n",
        "\n",
        "  #pre-defined 2\n",
        "  pair_str = sample_plausible_pair(scene_graph, subj=True)\n",
        "  if pair_str:\n",
        "    s, r = pair_str.split('_')\n",
        "\n",
        "    #we know it has synset since it is pre-condition for \"sample_plausible_pair\"\n",
        "    noun_synset = synset_mapping[s]\n",
        "\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"What is the {s} {r}?\",\n",
        "        failure_type=1,\n",
        "        failure_sub_type=2,\n",
        "        failure_reason=f\"No {s} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\":True, \"pair_sampled\": (s, r), \"noun_synset\": noun_synset}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "    #pre-defined 3\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Where is the {s}?\",\n",
        "        failure_type=1,\n",
        "        failure_sub_type=3,\n",
        "        failure_reason=f\"No {s} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\":True, \"noun_sampled\": s, \"noun_synset\": noun_synset}\n",
        "    )\n",
        "\n",
        "    pre_defined.append(q)\n",
        "\n",
        "  return pre_defined\n"
      ],
      "metadata": {
        "id": "Hz38LrmZ1UOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Type 2\n",
        "\n",
        "Definite singular reference to an object when the scene contains multiple instances of this object \n",
        "\n",
        "From question:\n",
        " 1. \"What is the man to the left of the pedestrians wearing?\" -> \"What is the woman to the left of the pedestrians wearing?\" or \n",
        "  \"What is the man to the left of the tunnel wearing?\", where there are men or tunnels in the scene.\n",
        "\n",
        "Pre-Defined:\n",
        "  1. Where is the [SUBJ/OBJ]? search for an object in the scene that have    multiple appearances and refer to it.\n",
        "  2. What is the [SUBJ] [REL]? additionally search for that object, a plausible relation.\n",
        "  3. Who is [REL] the [OBJ]?\n",
        "\n",
        "Notes for implementation:\n",
        "\n",
        "- for pre-defined we must filter non-countable nouns\n",
        "\n",
        "- for from_question the problem is that the triplet might solve the failure.\n",
        "e.g if we have multiple woman in the scene and we refer to \"woman to the left of the pedestraians\"\n",
        "the description become more specific and can potentially solve the ambiguity.\n",
        "another example - triplet is (man, to the left of, pedestraians) we search in the scene if first, there is another object or subject that hold to this relation and then if there is, count the number its appearances.\n",
        "however, if we generally count it, this can be misleading, since the subject or object can appear multiple times but not under the same relation.\n",
        "e.g triplets from scene graph (woman, to the left of, pedestraians), (woman, to the right of, pedestraians), (woman, wearing, pants)\n",
        "here we have multiple woman in the scene, but not to the left of the pedestrians.\n",
        "\n",
        "Solution: count object/subjects that only appear within a certain triplet.\n",
        "  e.g (woman, to the left of, pedestraians)\n",
        "  "
      ],
      "metadata": {
        "id": "S25WjPYUkmuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_representive(similar_set):\n",
        "  \"\"\"choose the representive of a similar set to be the most frequent name of the object that the similar set is representing\n",
        "    other possibility could be the majority from the canonical names (e.g trousers.n.01 => trousers) of representive synset\"\"\"\n",
        "\n",
        "  #majority over names\n",
        "  representive, count = Counter(chain(*[extract_names_from_VG_obj(x) for x in similar_set])).most_common(1)[0]\n",
        "  singular = inflect_eng.singular_noun(representive)\n",
        "\n",
        "  return singular if isinstance(singular, str) else representive"
      ],
      "metadata": {
        "id": "0Tu6euZZY2yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_2_from_questions(q_obj, id, triplet, aug_stats):\n",
        "  #for now we will pass on the implementation due to its complexity and belief that very few examples can be generated from this\n",
        "  return []"
      ],
      "metadata": {
        "id": "2yFOn_DfsZr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_2_pre_defined(scene_graph):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "  pre_defined = []\n",
        "\n",
        "  id = scene_graph[\"image_id\"]\n",
        "\n",
        "  #list of lists\n",
        "  similar_objects = compute_object_similar_groups(scene_graph)\n",
        "\n",
        "  obj = None\n",
        "  rel_obj = None\n",
        "  subj_rel = None\n",
        "\n",
        "  for similar_set in similar_objects:\n",
        "    if obj and rel_obj and subj_rel:\n",
        "      break\n",
        "\n",
        "    rep = select_representive(similar_set)\n",
        "\n",
        "    squeezed_set = merge_same_objects_in_similar_set(similar_set, delta=7)\n",
        "\n",
        "    if not is_mass_noun(rep) and len(squeezed_set) > 1: # number of appearances > 1\n",
        "\n",
        "      if obj is None:\n",
        "        obj = {\"candidate\": rep, \"similar_set\": similar_set}\n",
        "\n",
        "      if subj_rel is None:\n",
        "        rel = search_plausible_relation_for_subject(rep)\n",
        "        if rel:\n",
        "          subj_rel = {\"candidate\": f\"{rep}_{rel}\", \"similar_set\": similar_set}\n",
        "\n",
        "      if rel_obj is None:\n",
        "        rel = search_plausible_relation_for_object(rep)\n",
        "        if rel:\n",
        "          rel_obj = {\"candidate\": f\"{rel}_{rep}\", \"similar_set\": similar_set}\n",
        "\n",
        "  #pre-defined 1\n",
        "  if obj:\n",
        "    o = obj['candidate']\n",
        "\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Where is the {o}?\",\n",
        "        failure_type=2,\n",
        "        failure_sub_type=1,\n",
        "        failure_reason=f\"There are multiple {o} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"noun_sampled\": o ,\"similar_set\":obj['similar_set']}\n",
        "    )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "\n",
        "  #pre-defined 2\n",
        "  #e.g (knife, on top of) -> \"What is the knife on top of?\"\n",
        "  if subj_rel:\n",
        "    pair = subj_rel['candidate']\n",
        "\n",
        "    s, r = pair.split('_')\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"What is the {s} {r}?\",\n",
        "        failure_type=2,\n",
        "        failure_sub_type=2,\n",
        "        failure_reason=f\"There are multiple {s} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\": True, \"pair_sampled\": (s, r), \"similar_set\": subj_rel['similar_set']}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "\n",
        "  #pre-defined 3\n",
        "  #(on top of, desk) -> \"Who is on top of the desk?\"\n",
        "  if rel_obj:\n",
        "    pair = rel_obj['candidate']\n",
        "\n",
        "    r, o = pair.split('_')\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Who is {r} the {o}?\",\n",
        "        failure_type=2,\n",
        "        failure_sub_type=3,\n",
        "        failure_reason=f\"There are multiple {o} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\": False, \"pair_sampled\": (r, o), \"similar_set\": rel_obj['similar_set']}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "  return pre_defined"
      ],
      "metadata": {
        "id": "t5hCwquTncIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Type 3\n",
        "\n",
        "Definite plural reference to an object when the scene contains only one instance   \n",
        "\n",
        "From question:\n",
        "1. \"What is the man to the left of the pedestrians wearing?\" -> \n",
        "\"What are the men to the left of the pedestrians wearing?\", where there is only one man in the scene.\n",
        " \n",
        "Pre-Defined:\n",
        "1. Where is the [SUBJ/OBJ]?\n",
        "2. What is the [SUBJ] [REL]?\n",
        "3. Who is [REL] the [OBJ]?\n",
        "\n",
        "Notes for implementation:\n",
        "\n",
        "- pre-defined - we must filter non-countable nouns\n",
        "\n",
        "- from_question:\n",
        "  If we have triplet from question we need to sample an object from the scene\n",
        "  that have only one occurence (in total) in the scene.\n",
        "  however, the sampled object might not hold in the triplet in the image.\n",
        "  for example:\n",
        "  we have (man, to the left of, pedestraians) and we select 'woman' cause it appeared only one time\n",
        "  in the scene, although there is only one woman in the scene, it might not be to the left of the pedestrians.\n",
        "  \n",
        "  Solution: count object/subjects that only appear within a certain triplet.\n",
        "  e.g (woman, to the left of, pedestraians)"
      ],
      "metadata": {
        "id": "lNXChNy9kqG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_3_from_questions(q_obj, id, triplet, aug_stats):\n",
        "  #for now we will pass on the implementation due to its complexity and belief that very few examples can be generated from this\n",
        "  return []"
      ],
      "metadata": {
        "id": "Z0gE5MpnqDnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_3_pre_defined(scene_graph):\n",
        "  \"\"\"\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  pre_defined = []\n",
        "\n",
        "  id = scene_graph[\"image_id\"]\n",
        "\n",
        "  #list of lists\n",
        "  similar_objects = compute_object_similar_groups(scene_graph)\n",
        "\n",
        "  obj = None\n",
        "  rel_obj = None\n",
        "  subj_rel = None\n",
        "\n",
        "  for similar_set in similar_objects:\n",
        "    if obj and rel_obj and subj_rel:\n",
        "      break\n",
        "\n",
        "    rep = select_representive(similar_set)\n",
        "\n",
        "    if not is_mass_noun(rep) and len(similar_set) == 1:\n",
        "\n",
        "      #not needed to save similar set since it has length of 1\n",
        "      if obj is None:\n",
        "        obj = rep\n",
        "\n",
        "      if subj_rel is None:\n",
        "        rel = search_plausible_relation_for_subject(rep)\n",
        "        if rel is not None:\n",
        "          subj_rel = f\"{rep}_{rel}\"\n",
        "\n",
        "      if rel_obj is None:\n",
        "        rel = search_plausible_relation_for_object(rep)\n",
        "        if rel is not None:\n",
        "          rel_obj = f\"{rel}_{rep}\"\n",
        "\n",
        "  #pre-defined 1\n",
        "  if obj:\n",
        "    obj_plural = inflect_eng.plural_noun(obj)\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Where are the {obj_plural}?\",\n",
        "        failure_type=3,\n",
        "        failure_sub_type=1,\n",
        "        failure_reason=f\"There is only one {obj} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"noun_sampled\": obj}\n",
        "\n",
        "    )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "\n",
        "  #pre-defined 2\n",
        "  #e.g (knives, on top of the) -> What are the knives on top of ?\n",
        "\n",
        "  if subj_rel:\n",
        "    s, r = subj_rel.split('_')\n",
        "    s_plural = inflect_eng.plural_noun(s)\n",
        "\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"What are the {s_plural} {r}?\",\n",
        "        failure_type=3,\n",
        "        failure_sub_type=2,\n",
        "        failure_reason=f\"There is only one {s} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\": True, \"pair_sampled\": (s, r)}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "\n",
        "  #pre-defined 3\n",
        "  #e.g (on top of, desks) -> \"Who is on top of the desks?\"\n",
        "  if rel_obj:\n",
        "    r, o = rel_obj.split('_')\n",
        "    o_plural = inflect_eng.plural_noun(o)\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Who is {r} the {o_plural}?\",\n",
        "        failure_type=3,\n",
        "        failure_sub_type=3,\n",
        "        failure_reason=f\"There is only one {o} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\": False, \"pair_sampled\": (r, o)}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "  return pre_defined"
      ],
      "metadata": {
        "id": "3LZoA_YkK0UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Type 4\n",
        "\n",
        "Definite complex reference to an object that exists in the scene but the instance does not hold in the relation expressed in the description.  \n",
        "From questions:  \n",
        "1. \"What is the man to the left of the pedestrians wearing?\" -> \"What is the man to the right of the pedestrians wearing?\"  \n",
        "\n",
        "Pre-Defined:  \n",
        "1. Where is the [SUBJ] [REL] the [OBJ]? - sample triplet from the scene graph, substitute relation e.g (man,wearing,jacket) -> (Where is the man throwing the jacket?), USE SUBSTITUTION between subject and object if it is they are plausible pair in visual genome\n",
        "2. What does the [S1] [R1] the [O1] [R2]? - get compositional triplets e.g [(s1,r1,o1), (s1,r2,o2)] from the scene graph and choose new relation to trigger triplet failure \n",
        "3. What is the [SUBJ] [REL]? - sample triplet from the scene graph, substitute relation e.g (man,wearing,jacket) -> (\"What is the man throwing?\")\n",
        "4. Who is [REL] the [OBJ]? - sample triplet from the scene graph, substitute relation e.g (man,wearing,jacket) -> (\"Who is throwing the jacket?\")\n"
      ],
      "metadata": {
        "id": "bbnZ5GrXksJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_4_from_questions(q_obj, id, triplet, aug_stats):\n",
        "  \n",
        "  from_questions = []\n",
        "\n",
        "  #from_questions\n",
        "  subj, rel, obj = triplet\n",
        "  scene_graph = extract_scene_graph_from_question(q_obj)\n",
        "\n",
        "  if scene_graph is not None:\n",
        "    package = choose_relation(\"entailment\", id, scene_graph, subj, rel, obj)\n",
        "\n",
        "    if package is not None:\n",
        "      aug_rel, nli_label, sim_score = package\n",
        "\n",
        "      lemmas_before = aug_stats['lemma']\n",
        "      q_new, is_suc = augment(q_obj, rel, aug_rel, aug_stats)\n",
        "\n",
        "      if is_suc:\n",
        "\n",
        "        q_new_gec, lev_dist = fix_grammar(q_new)\n",
        "\n",
        "        q = AugmentQuestion(\n",
        "            q=q_new_gec,\n",
        "            failure_type=4,\n",
        "            failure_reason=f\"No {subj} {aug_rel} {obj} in image\",\n",
        "            q_gec=q_new,\n",
        "            is_lemmatised_aug=(aug_stats['lemma'] - lemmas_before == 1),\n",
        "            origin_id=id,\n",
        "            image_id=q_obj['imageId'],\n",
        "            generation_type=\"from_questions\",\n",
        "            properties={\"triplet_sampled\": (subj, aug_rel, obj)}\n",
        "        )\n",
        "\n",
        "        from_questions.append(q)\n",
        "\n",
        "  return from_questions\n"
      ],
      "metadata": {
        "id": "hTnTYZsUjuQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_compositional_pair_iterator(pair_lst):\n",
        "  \"\"\"\n",
        "  This function computes list of pairs between elements of pair_lst\n",
        "  in a way that prevent the pipeline from generating duplicate questions.\n",
        "  e.g man -> [(carries, backpack), (wears, sneakers), (wears, backpack), (at, crosswalk)]\n",
        "  if we pair (carries, backpack) with (wears, sneakers), then we pair (carries, backpack) and (wears, backpack)\n",
        "  then, if we sample the same augmented relation for both - lets say \"opening\", we will get the same question:\n",
        "  (carries, backpack) + (wears, sneakers) = \"What does the man opening the backpack wears?\"\n",
        "  (carries, backpack) + (wears, backpack) = \"What does the man opening the backpack wears?\"\n",
        "  \"\"\"\n",
        "  combs = []\n",
        "  for i, x in enumerate(pair_lst):\n",
        "    x_combs = []\n",
        "    for j, y in enumerate(pair_lst):\n",
        "      if i!=j:\n",
        "        is_same_rel_exist = any([y[0] == z[0] for z in x_combs])\n",
        "        is_same_rel_as_x = x[0] == y[0]\n",
        "        if not is_same_rel_as_x and not is_same_rel_exist:\n",
        "          x_combs.append(y)\n",
        "\n",
        "    x_combs = [(x, z) for z in x_combs]\n",
        "      \n",
        "    combs.extend(x_combs)\n",
        "  \n",
        "  return combs"
      ],
      "metadata": {
        "id": "TUSlrL-IlX3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_compositional_pair_iterator([('carries', 'backpack'), ('wears', 'sneakers'), ('wears', 'backpack'), ('at', 'crosswalk')])"
      ],
      "metadata": {
        "id": "9BBIlxbroe_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_4_pre_defined(scene_graph):\n",
        "\n",
        "  pre_defined = []\n",
        "\n",
        "  id = scene_graph[\"image_id\"]\n",
        "  \n",
        "  #pre-defined\n",
        "  scene_graph_triplets = extract_triplets_from_scene_graph(scene_graph)\n",
        "\n",
        "  np.random.shuffle(scene_graph_triplets)\n",
        "  \n",
        "  logger.debug(f\"starting pre-defind 1\")\n",
        "  subs_triplet = None\n",
        "  for t in scene_graph_triplets:\n",
        "    s, r, o = t\n",
        "\n",
        "    if is_plausible_pair(o, s): #subject and object substitution\n",
        "\n",
        "      aug_rel = sample_embedded_relation_randomly(scene_graph, o, s)\n",
        "      \n",
        "      if aug_rel is not None:\n",
        "        subs_triplet = (o, aug_rel, s)\n",
        "\n",
        "\n",
        "  if subs_triplet:\n",
        "    s, r, o = subs_triplet\n",
        "    #pre-defined 1\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"Where is the {s} {r} the {o}?\",\n",
        "        failure_type=4,\n",
        "        failure_sub_type=1,\n",
        "        failure_reason=f\"No {s} {r} {o} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"triplet_sampled\": (s, r, o)}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "  \n",
        "  # new_triplet = None\n",
        "  # for t in scene_graph_triplets:\n",
        "  #   s, r, o = t\n",
        "\n",
        "  #   package = choose_relation(\"entailment\", id, scene_graph, s, r, o)\n",
        "  #   if package is not None:\n",
        "  #     aug_rel, nli_label, sim_score = package\n",
        "\n",
        "  #     new_triplet = (s, aug_rel, o)\n",
        "  #     break\n",
        "          \n",
        "\n",
        "  # if new_triplet:\n",
        "  #   s, r, o = new_triplet\n",
        "\n",
        "  logger.debug(f\"starting pre-defind 3 and 4\")\n",
        "  subj_pair, obj_pair = sample_plausible_pair_from_scene_graph(scene_graph)\n",
        "\n",
        "  if subj_pair:\n",
        "\n",
        "    s, r = subj_pair\n",
        "\n",
        "    #pre-defined 3\n",
        "    q = AugmentQuestion(\n",
        "        q=f\"What is the {s} {r}?\",\n",
        "        failure_type=4,\n",
        "        failure_sub_type=3,\n",
        "        failure_reason=f\"No {s} {r} in image\",\n",
        "        origin_id=id,\n",
        "        image_id=id,\n",
        "        generation_type=\"pre_defined\",\n",
        "        properties={\"is_subj_aug\": True, \"pair_sampled\": (s, r)}\n",
        "        )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "  if obj_pair:\n",
        "\n",
        "    r, o = obj_pair\n",
        "\n",
        "    pp_r = transform_present_progressive(r)\n",
        "\n",
        "    #pre-defined 4 \n",
        "    q = AugmentQuestion(\n",
        "      q=f\"Who is {pp_r} the {o}?\",\n",
        "      failure_type=4,\n",
        "      failure_sub_type=4,\n",
        "      failure_reason=f\"Nothing is {r} {o} in image\",\n",
        "      origin_id=id,\n",
        "      image_id=id,\n",
        "      generation_type=\"pre_defined\",\n",
        "      properties={\"is_subj_aug\": False, \"triplet_sampled\": (r, o)}\n",
        "    )\n",
        "    pre_defined.append(q)\n",
        "\n",
        "\n",
        "\n",
        "  logger.debug(f\"starting pre-defind 2\")\n",
        "  #pre-defined 2\n",
        "  subj2pairs = generate_subjects_2_pair(scene_graph) # s-> [(r1,o1),(r2,o2),..]\n",
        "\n",
        "  # logger.debug(subj2pairs)\n",
        "  # logger.debug('merging')\n",
        "\n",
        "  #merge the same pairs to prevent duplicates\n",
        "  subj2pairs = {k:set(v) for k,v in subj2pairs.items()}\n",
        "\n",
        "  # logger.debug(subj2pairs)\n",
        "\n",
        "  # logger.debug(f\"finished s2pairs map\")\n",
        "  \n",
        "\n",
        "  for s, pair_lst in subj2pairs.items():\n",
        "    if len(pair_lst) > 1:\n",
        "\n",
        "      combs = compute_compositional_pair_iterator(pair_lst) #all pairs in pair_list\n",
        "\n",
        "      # logger.debug(f'combs--{s}')\n",
        "      # logger.debug(combs)\n",
        "\n",
        "      for p1,p2 in combs:\n",
        "        \n",
        "        # logger.debug('-'*80)\n",
        "        # logger.debug(f\"p1={p1}, p2={p2}\")\n",
        "\n",
        "        r1,o1 = p1\n",
        "        r2,o2 = p2\n",
        "\n",
        "        package = choose_relation(\"entailment\", id, scene_graph, s, r1, o1)\n",
        "        if package is not None:\n",
        "          aug_rel, nli_label, sim_score = package\n",
        "\n",
        "          new_triplet = (s, aug_rel, o1)\n",
        "\n",
        "          \n",
        "          q = AugmentQuestion(\n",
        "            q=f\"What does the {s} {aug_rel} the {o1} {r2}?\",\n",
        "            failure_type=4,\n",
        "            failure_sub_type=2,\n",
        "            failure_reason=f\"No {s} {aug_rel} {o1} in image\",\n",
        "            origin_id=id,\n",
        "            image_id=id,\n",
        "            generation_type=\"pre_defined\",\n",
        "            properties={\"triplet_sampled\": new_triplet, \"chain_triplet\": (s,r2,o2), \"subst_rel\": r1}\n",
        "          )\n",
        "\n",
        "          # logger.debug(f\"{(r1, o1)}-->{(aug_rel, o1)}, chain-pair:{(r2,o2)}. Q: {q.q}\")\n",
        "\n",
        "          pre_defined.append(q)\n",
        "\n",
        "\n",
        "\n",
        "        # package = choose_relation(\"entailment\", id, scene_graph, s, r2, o2)\n",
        "        # if package is not None:\n",
        "        #   aug_rel, nli_label, sim_score = package\n",
        "\n",
        "        #   new_triplet = (s, aug_rel, o2)\n",
        "\n",
        "        #   q = AugmentQuestion(\n",
        "        #     q=f\"What does the {s} {aug_rel} the {o2} {r1}?\",\n",
        "        #     failure_type=4,\n",
        "        #     failure_reason=f\"No {s} {aug_rel} {o2} in image\",\n",
        "        #     origin_id=id,\n",
        "        #     image_id=id,\n",
        "        #     generation_type=\"pre_defined\",\n",
        "        #     properties={\"triplet_sampled\": new_triplet, \"chain_triplet\": (s,r1,o1), \"subst_rel\": r2}\n",
        "        #   )\n",
        "\n",
        "        #   logger.debug(f\"{(r2, o2)}-->{(aug_rel, o2)}, chain-pair:{(r1,o1)}. Q: {q.q}\")\n",
        "\n",
        "        #   pre_defined.append(q)\n",
        "\n",
        "      break # we only want to try generate from 1 pair list to avoid heavy computations\n",
        "\n",
        "\n",
        "  return pre_defined\n"
      ],
      "metadata": {
        "id": "JOgA7RfwY-WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Type 5\n",
        "Definitive complex reference to an object or subject that exists in the scene, \n",
        "  the instance does hold in the relation expressed, but the relation refer to multiple options.\n",
        "  We only use predefined here:\n",
        "  1. What does the [SUBJ] [REL] ? - given a scene graph, search for triplets\n",
        "  with multiple object options => (biker, wearing, jacket/pants/shoes) -> What does the biker wear?\n",
        "  or (biker, has, jacket/pants/shoes)\n",
        "  2. Who is [REL] the [OBJ]? -  given a question q, search for triplets with multiple\n",
        "  object options => (biker/boy/woman, wearing, jacket) -> Who is wearing the jacket?"
      ],
      "metadata": {
        "id": "Bl00ohcn-oG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_5_from_questions(q_obj, id, triplet, aug_stats):\n",
        "  return []"
      ],
      "metadata": {
        "id": "pmZ32D-IhOOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_type_5_pre_defined(scene_graph):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  id = scene_graph[\"image_id\"]\n",
        "\n",
        "  def generate_multiple_object_question(objects, subj_groups):\n",
        "    qs = []\n",
        "\n",
        "    for group in subj_groups:\n",
        "\n",
        "      if len(group) > 1: #if there are atleast 2 objects fit to (subj, rel, *), where * is unique object\n",
        "\n",
        "        some_triplet = group[0] # all subjects and relations in group are the same\n",
        "        s_id = some_triplet['subject_id']\n",
        "        r = str(some_triplet['predicate']).lower()\n",
        "\n",
        "        objects_ids = [x[\"object_id\"] for x in group]\n",
        "\n",
        "        #extract objects\n",
        "        objects_in_group = from_object_id_to_object_obj(objects, objects_ids)\n",
        "\n",
        "        logger.debug(f\"objects-in-group: {objects_in_group}\")\n",
        "\n",
        "        combs = combinations(objects_in_group, 2)\n",
        "\n",
        "        for o1, o2 in combs:\n",
        "          \n",
        "          # if are_objects_comparable(o1, o2) and are_two_objects_similar(o1, o2):\n",
        "          #   logger.debug(f\"comparable, but similar: {[o1,o2]}\")\n",
        "\n",
        "          if are_objects_comparable(o1, o2) and not are_two_objects_similar(o1, o2):\n",
        "            # if two objects are not similar, it means the triplet holds for atleast two unique objects\n",
        "            #thus, we can generate a question with multiple answers based on that idea\n",
        "\n",
        "            #pre-defined 1\n",
        "            o1_id = o1['object_id']\n",
        "            o2_id = o2['object_id']\n",
        "\n",
        "            nouns_list = from_object_id_to_string(objects, [o1_id, o2_id, s_id])\n",
        "\n",
        "            logger.debug(f\"failure nouns_list = (obj1,obj2, subj): {nouns_list}\")\n",
        "\n",
        "            if nouns_list is not None and len(nouns_list) == 3:\n",
        "              o1_name,o2_name, subj_name = nouns_list\n",
        "\n",
        "              objects_names = from_object_id_to_string(objects, objects_ids)\n",
        "\n",
        "              qs.append(AugmentQuestion(\n",
        "                  q=f\"What does the {subj_name} {r}?\",\n",
        "                  failure_type=5,\n",
        "                  failure_sub_type=1,\n",
        "                  failure_reason=f\"The question refer to atleast two objects: {[o1_name, o2_name]} in the image\",\n",
        "                  origin_id=id,\n",
        "                  image_id=id,\n",
        "                  generation_type=\"pre_defined\",\n",
        "                  properties={\"is_subj_aug\": True, \"pair_sampled\": (subj_name, r), \"similar_set\": group}\n",
        "                  ))\n",
        "              \n",
        "              # the group contains triplets with the same rel and subj but with different objects, since the generated question is asking\n",
        "              # about the object, if we won't break the loop we will generate duplicate questions\n",
        "              break\n",
        "              \n",
        "    return qs\n",
        "\n",
        "  def generate_multiple_subject_question(objects, obj_groups):\n",
        "    \"\"\"\n",
        "    When generating a multiple subject question, we need to pay attention to which kind of subjects\n",
        "    withold in the same triplet. \n",
        "    If there are multiple pronouns or people/person, the question must have \"interrogative pronoun\"\n",
        "    such as \"Who, Which, Whom, What, Whose\". Else, use \"What, Which\"\n",
        "    e.g (can, lying on, grass), (dog, lying on, grass), (cat, lying on, grass), (girl, lying on, grass), (they, lying on, grass)\u0003\n",
        "    1. \"What is lying on the grass?\" - fits for (can, lying on, grass), (dog, lying on, grass), (cat, lying on, grass)\n",
        "    2. \"Who is lying on the grass?\" - fits for (girl, lying on, grass), (they, lying on, grass)\u0003\n",
        "    \"\"\"\n",
        "    qs = []\n",
        "\n",
        "    for group in obj_groups:\n",
        "\n",
        "      if len(group) > 1: #if there are atleast 2 subjects fit to (*, rel, obj), where * is unique subject\n",
        "\n",
        "        some_triplet = group[0] # all objects and relations in group are the same\n",
        "        o_id = some_triplet['object_id']\n",
        "        r = str(some_triplet['predicate']).lower()\n",
        "\n",
        "        subjects_ids = [x[\"subject_id\"] for x in group]\n",
        "\n",
        "        #extract subjects\n",
        "        subjects_in_group = from_object_id_to_object_obj(objects, subjects_ids)\n",
        "\n",
        "        logger.debug(f\"subjects-in-group: {subjects_in_group}\")\n",
        "\n",
        "        #split - explanation above\n",
        "        inter, other = split_object_similar_set(subjects_in_group)\n",
        "\n",
        "        for subjects, is_interrogative in zip([inter, other], [True, False]):\n",
        "\n",
        "          if len(subjects) <= 1:\n",
        "            continue\n",
        "\n",
        "          combs = combinations(subjects, 2)\n",
        "\n",
        "          for s1, s2 in combs:\n",
        "\n",
        "            # if are_objects_comparable(s1, s2) and are_two_objects_similar(s1, s2):\n",
        "            #   logger.debug(f\"comparable, but similar: {[s1,s2]}\")\n",
        "\n",
        "            if are_objects_comparable(s1, s2) and not are_two_objects_similar(s1, s2):\n",
        "              # if two subjects are not similar, it means the triplet holds for atleast two unique subject\n",
        "              #thus, we can generate a question with multiple answers based on that idea\n",
        "\n",
        "              #pre-defined 2\n",
        "              s1_id = s1['object_id']\n",
        "              s2_id = s2['object_id']\n",
        "\n",
        "              nouns_list = from_object_id_to_string(objects, [s1_id, s2_id, o_id])\n",
        "\n",
        "              logger.debug(f\"failure nouns_list = (subj1,sub2,obj): {nouns_list}\")\n",
        "\n",
        "              if nouns_list is not None and len(nouns_list) == 3:\n",
        "                s1_name,s2_name, obj_name = nouns_list\n",
        "\n",
        "                subjects_names = from_object_id_to_string(objects, subjects_ids)\n",
        "\n",
        "                WH = 'Who' if is_interrogative else 'What'\n",
        "\n",
        "                qs.append(AugmentQuestion(\n",
        "                    q=f\"{WH} is {r} the {obj_name}?\",\n",
        "                    failure_type=5,\n",
        "                    failure_sub_type=2,\n",
        "                    failure_reason=f\"The question refer to atleast two subjects: {[s1_name, s2_name]} in the image\",\n",
        "                    origin_id=id,\n",
        "                    image_id=id,\n",
        "                    generation_type=\"pre_defined\",\n",
        "                    properties={\"is_subj_aug\": False, \"pair_sampled\": (r, obj_name), \"similar_set\": group}\n",
        "                    ))\n",
        "                \n",
        "                # the group contains triplets with the same rel and obj but with different subjects, since the generated question is asking\n",
        "                # about the subject, if we won't break the loop we will generate duplicate questions\n",
        "                break \n",
        "              \n",
        "              \n",
        "    return qs\n",
        "\n",
        "\n",
        "\n",
        "  pre_defined = []\n",
        "\n",
        "\n",
        "  subj_groups, obj_groups = compute_triplet_similar_groups(scene_graph)\n",
        "\n",
        "  objects = scene_graph[\"objects\"]\n",
        "\n",
        "  qs = generate_multiple_object_question(objects, subj_groups)\n",
        "\n",
        "  pre_defined.extend(qs)\n",
        "\n",
        "  qs = generate_multiple_subject_question(objects, obj_groups)\n",
        "\n",
        "  pre_defined.extend(qs)\n",
        "\n",
        "\n",
        "  return pre_defined"
      ],
      "metadata": {
        "id": "OioqkWwFyouf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Factory Pipe"
      ],
      "metadata": {
        "id": "DvJ0KCBuLkC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predefined(scene_graph) -> List[AugmentQuestion]:\n",
        "  questions = []\n",
        "\n",
        "  ## type 1\n",
        "  logger.debug('Generating Type 1...')\n",
        "  questions += gen_type_1_pre_defined(scene_graph)\n",
        "\n",
        "  ## type 2\n",
        "  logger.debug('Generating Type 2...')\n",
        "  questions += gen_type_2_pre_defined(scene_graph)\n",
        "\n",
        "  ## type 3\n",
        "  logger.debug('Generating Type 3...')\n",
        "  questions += gen_type_3_pre_defined(scene_graph)\n",
        "\n",
        "  ## type 4\n",
        "  logger.debug('Generating Type 4...')\n",
        "  questions += check_timing(gen_type_4_pre_defined, scene_graph)\n",
        "  # questions += gen_type_4_pre_defined(scene_graph)\n",
        "\n",
        "  ## type 5\n",
        "  logger.debug('Generating Type 5...')\n",
        "  questions += gen_type_5_pre_defined(scene_graph)\n",
        "\n",
        "  return questions"
      ],
      "metadata": {
        "id": "NKYX-cNdWeRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_from_questions(q_obj, id, triplet, aug_stats, subj_has_multiple_presuppositions=False) -> List[AugmentQuestion]:\n",
        "  \n",
        "  questions = []\n",
        "\n",
        "  ## type 1\n",
        "  logger.debug('Generating Type 1...')\n",
        "  questions += gen_type_1_from_questions(q_obj, id, triplet, aug_stats, subj_has_multiple_presuppositions=subj_has_multiple_presuppositions)\n",
        "\n",
        "  ## type 2\n",
        "  logger.debug('Generating Type 2...')\n",
        "  questions += gen_type_2_from_questions(q_obj, id, triplet, aug_stats)\n",
        "\n",
        "  ## type 3\n",
        "  logger.debug('Generating Type 3...')\n",
        "  questions += gen_type_3_from_questions(q_obj, id, triplet, aug_stats)\n",
        "\n",
        "  ## type 4\n",
        "  logger.debug('Generating Type 4...')\n",
        "  questions += gen_type_4_from_questions(q_obj, id, triplet, aug_stats)\n",
        "\n",
        "  ## type 5\n",
        "  logger.debug('Generating Type 5...')\n",
        "  questions += gen_type_5_from_questions(q_obj, id, triplet, aug_stats)\n",
        "\n",
        "  return questions\n"
      ],
      "metadata": {
        "id": "GYSOU_A0d9Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "        self.q = q\n",
        "        self.q_gec = q_gec\n",
        "        self.failure_type = failure_type\n",
        "        self.failure_reason = failure_reason\n",
        "        self.gec_dist = gec_dist\n",
        "        self.is_lemmatized_aug = is_lemmatised_aug\n",
        "        self.generation_type = generation_type\n",
        "        self.origin_id = origin_id\n",
        "        self.properties = properties\n",
        "\"\"\"\n",
        "\n",
        "def generation_summary(questions: List[AugmentQuestion]):\n",
        "  logger.debug(\"--Generation Summary--\")\n",
        "  logger.debug(f\"Total Generated: {len(questions)}\")\n",
        "  logger.debug(f\"Types Distribution: {Counter([q.failure_type for q in questions])}\")\n",
        "\n",
        "  for i in range(1,6):\n",
        "    qs_type_i = [q for q in questions if q.failure_type == i]\n",
        "    are_all_have_sub_types = [q.failure_sub_type is not None for q in qs_type_i]\n",
        "    if are_all_have_sub_types:\n",
        "      logger.debug(f\"Type {i} Sub-Types Distribution: {Counter([q.failure_sub_type for q in qs_type_i])}\")\n",
        "\n",
        "  for i,q in enumerate(questions):\n",
        "    logger.debug(f\"Type=[{q.failure_type}][{q.failure_sub_type if q.failure_sub_type else -1}] Failure=[{q.failure_reason}], {q.q}\")\n",
        "\n",
        "  unique_properties_keys = sorted(set(chain(*[q.properties.keys() for q in questions])))\n",
        "  props_summary = {}\n",
        "\n",
        "  for key in unique_properties_keys:\n",
        "    props_summary[key] = [q.properties[key] for q in questions if key in q.properties]\n",
        "\n",
        "  logger.debug(f\"Properties Distribution: {props_summary}\")"
      ],
      "metadata": {
        "id": "x9kxS7zT4o0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "3Q-IncoMKeQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre Defined Pipeline"
      ],
      "metadata": {
        "id": "4sCEcoAK2nLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predefined_pipeline(path_to_data: str, resume_obj: dict = None):\n",
        "    \"\"\"\n",
        "    Pipeline to iterate over scene-graphs and generate pre-defined type of questions from each\n",
        "    :param path_to_data: path to where the json of the data exists (questions objects)\n",
        "    :param resume_obj: encapuslates all what necessary to resume pipeline from where it starts\n",
        "    \"\"\"\n",
        "    #TODO: put your base folder path, where it will create all files\n",
        "    base_folder = f''\n",
        "    logger_file_mode = 'a'\n",
        "\n",
        "    if resume_obj is None:\n",
        "\n",
        "      dt_now = str(dt.datetime.now())\n",
        "\n",
        "      folder = base_folder + dt_now\n",
        "\n",
        "      data_folder = folder+'/data/'\n",
        "\n",
        "      if not os.path.exists(data_folder):\n",
        "        os.makedirs(data_folder)\n",
        "      \n",
        "      log_path = f'{folder}/output.log'\n",
        "\n",
        "      f = open(log_path, 'w')\n",
        "      f.close()\n",
        "             \n",
        "      # set seeds\n",
        "      np.random.seed(42)\n",
        "\n",
        "      numpy_random_state = np.random.get_state()\n",
        "\n",
        "      # np.save(folder+'/random_state.npy', numpy_random_state)\n",
        "\n",
        "      #setting stats\n",
        "      stats_path = f'{folder}/stats.json'\n",
        "      stats = {\n",
        "          \"iterated\": 0, #total scene graph iterated\n",
        "          \"generated\": 0, #total questions generated\n",
        "          \"types_dist\": Counter({k:0 for k in range(1,6)}),\n",
        "          \"sub_type_dist\": Counter({k: Counter() for k in range(1,6)}),\n",
        "          \"complete_ids\": [] # finished scene graph ids\n",
        "      }\n",
        "      \n",
        "\n",
        "    else:\n",
        "      data_folder = resume_obj['data_folder']\n",
        "      log_path = resume_obj['log_path']\n",
        "      stats_path = resume_obj['stats_path']\n",
        "      folder = resume_obj['folder_path']\n",
        "\n",
        "\n",
        "      if log_path is None:\n",
        "        logger_file_mode = 'w'\n",
        "        dt_now = str(dt.datetime.now())\n",
        "        log_path = f'{folder}/output-{dt_now}.log'\n",
        "      \n",
        "      with open(stats_path) as f:\n",
        "        stats = json.load(f)\n",
        "\n",
        "      random_state_path = resume_obj['random_state_path']\n",
        "      with open(random_state_path, 'rb') as f:\n",
        "        numpy_random_state = pickle.load(f)\n",
        "        np.random.set_state(numpy_random_state)\n",
        "    \n",
        "\n",
        "    global logger\n",
        "    logger = logging.getLogger('Generator')\n",
        "    logger.setLevel(\"DEBUG\")\n",
        "    logger.handlers.clear()\n",
        "    output_file_handler = logging.FileHandler(log_path, mode=logger_file_mode, encoding=None, delay=False)\n",
        "    logger.addHandler(output_file_handler)\n",
        "\n",
        "    logger.debug(f\"data_folder=[{data_folder}], log_path=[{log_path}], stats_path=[{stats_path}]\")\n",
        "    logger.debug(f\"Iterated=[{stats['iterated']}], Completed: [{len(stats['complete_ids'])}], Generated: [{stats['generated']}]\")\n",
        "\n",
        "    logger.debug(\"Begin Pre-Defined Questions Generation Pipeline\")\n",
        "    with open(path_to_data) as f:\n",
        "        items = ijson.items(f, \"item\")\n",
        "        for i, scene_graph_obj in tqdm(enumerate(items)):\n",
        "\n",
        "          id = scene_graph_obj['image_id']\n",
        "          \n",
        "          if id in stats['complete_ids']: #skipping ids if resumed\n",
        "            continue\n",
        "\n",
        "          stats['iterated'] += 1\n",
        "          logger.debug(\"=\" * 80)\n",
        "\n",
        "          try: \n",
        "\n",
        "              logger.debug(f'Generating for image-id={id}')\n",
        "              start = timer()\n",
        "              questions = generate_predefined(scene_graph_obj)\n",
        "              logger.debug(f\"generation time taken: [{timer() - start}] seconds\")\n",
        "\n",
        "              generation_summary(questions)\n",
        "\n",
        "              # emit\n",
        "              with open(data_folder+f\"{id}.json\", 'w') as nf:\n",
        "                q_id_range = range(stats['generated'], stats['generated']+len(questions))\n",
        "                #dict-format: {num_of_successfully_questions}->question object\n",
        "                json.dump({k:v for k,v in zip(q_id_range, questions)}, nf, cls=ObjectEncoder)\n",
        "                stats['generated'] += len(questions)\n",
        "\n",
        "              # for q in questions: \n",
        "              #   #name-format: {num_of_successfully_questions}_{origin_id}\n",
        "              #   with open(data_folder+f\"{stats['generated']}_{id}.json\", 'w') as nf:\n",
        "              #     json.dump(q, nf, cls=ObjectEncoder)\n",
        "                \n",
        "              #   stats['generated'] += 1\n",
        "\n",
        "              #mark finished\n",
        "              stats['complete_ids'].append(id)\n",
        "\n",
        "              # update stats\n",
        "              stats[\"types_dist\"].update(Counter([q.failure_type for q in questions]))\n",
        "\n",
        "              for i in range(1,6):\n",
        "                qs_type_i = [q for q in questions if q.failure_type == i]\n",
        "                are_all_have_sub_types = [q.failure_sub_type is not None for q in qs_type_i]\n",
        "                if are_all_have_sub_types:\n",
        "                  stats[\"sub_type_dist\"][i].update(Counter([q.failure_sub_type for q in qs_type_i]))\n",
        "              \n",
        "              # save state after stochastic methods\n",
        "              numpy_random_state = np.random.get_state()\n",
        "              with open(folder+'/random_state.pkl', 'wb') as bf:\n",
        "                pickle.dump(numpy_random_state, bf)\n",
        "              # np.save(folder+'/random_state.npy', numpy_random_state)\n",
        "\n",
        "              #update stats\n",
        "              with open(stats_path, 'w') as xf:\n",
        "                  json.dump(stats, xf)\n",
        "                              \n",
        "\n",
        "          except Exception as e:\n",
        "              logger.debug(f\"Raised exception {e} on scene graph object id {id}, continue processing...\")\n",
        "              raise e\n",
        "\n",
        "          logger.debug(f\"Iterated=[{stats['iterated']}], Completed: [{len(stats['complete_ids'])}], Generated: [{stats['generated']}]\")\n",
        "          gen_ratio = stats['generated']/len(stats['complete_ids']) if len(stats['complete_ids']) > 0 else 0\n",
        "          logger.debug(f\"Generation Ratio(generated/iterated): {gen_ratio}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yrzz1tgko4kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to Visual Genome scene graphs\n",
        "train_sg_path = '.../train_gqa_vg_scene_graphs.json'\n",
        "predefined_pipeline(path_to_data=train_sg_path)"
      ],
      "metadata": {
        "id": "5knEIskiuBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From Questions Pipeline"
      ],
      "metadata": {
        "id": "j4AQlad52qNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def from_questions_pipeline(path_to_data: str, resume_obj: dict = None):\n",
        "    \"\"\"\n",
        "    Pipeline to iterate over questions and generate from_questions type of questions from each\n",
        "    :param path_to_data: path to where the json of the data exists (questions objects)\n",
        "    :param resume_obj: encapuslates all what necessary to resume pipeline from where it starts\n",
        "    \"\"\"\n",
        "    #TODO: put your base folder path, where it will create all files\n",
        "    base_folder = f''\n",
        "\n",
        "    if resume_obj is None:\n",
        "\n",
        "      dt_now = str(dt.datetime.now())\n",
        "\n",
        "      folder = base_folder + dt_now\n",
        "\n",
        "      data_folder = folder+'/data/'\n",
        "\n",
        "      if not os.path.exists(data_folder):\n",
        "        os.makedirs(data_folder)\n",
        "      \n",
        "      log_path = f'{folder}/output.log'\n",
        "\n",
        "      f = open(log_path, 'w')\n",
        "      f.close()\n",
        "\n",
        "      # set seeds\n",
        "      np.random.seed(42)\n",
        "\n",
        "      numpy_random_state = np.random.get_state()\n",
        "\n",
        "      #setting stats\n",
        "      stats_path = f'{folder}/stats.json'\n",
        "      stats = {\n",
        "          \"augment_stats\": {\"lemma\": 0, \"original\": 0, \"failed\": 0}, #distribution of augmentation stats of 'generated' questions\n",
        "          \"iterated\": 0, #num question iterated from the dataset that fit to the condition of query-rel\n",
        "          \"generated\": 0, # total generated questions\n",
        "          \"types_dist\": Counter(),\n",
        "          \"questions_extract_relations_fail\": 0, #num questions iterated from the dataset and failed on relations extraction\n",
        "          \"complete_ids\": [] #num questions iterated from the dataset and were used for augmentation\n",
        "      }\n",
        "      \n",
        "\n",
        "    else:\n",
        "      data_folder = resume_obj['data_folder']\n",
        "      log_path = resume_obj['log_path']\n",
        "      stats_path = resume_obj['stats_path']\n",
        "      folder = resume_obj['folder_path']\n",
        "      with open(stats_path) as f:\n",
        "        stats = json.load(f)\n",
        "      \n",
        "      random_state_path = resume_obj['random_state_path']\n",
        "      with open(random_state_path, 'rb') as f:\n",
        "        numpy_random_state = pickle.load(f)\n",
        "        np.random.set_state(numpy_random_state)\n",
        "      \n",
        "    global logger\n",
        "    logger = logging.getLogger('Generator')\n",
        "    logger.setLevel(\"DEBUG\")\n",
        "    logger.handlers.clear()\n",
        "    output_file_handler = logging.FileHandler(log_path)\n",
        "    logger.addHandler(output_file_handler)\n",
        "\n",
        "\n",
        "    logger.debug(f\"data_folder=[{data_folder}], log_path=[{log_path}], stats_path=[{stats_path}]\")\n",
        "    logger.debug(f\"Iterated=[{stats['iterated']}], Completed: [{len(stats['complete_ids'])}], Generated: [{stats['generated']}]\")\n",
        "\n",
        "\n",
        "    logger.debug(\"Begin From Questions Generation Pipeline\")\n",
        "    with open(path_to_data) as f:\n",
        "        qs = ijson.kvitems(f, '')\n",
        "\n",
        "        for i, (id, q_obj) in tqdm(enumerate(qs)):\n",
        "          \n",
        "          if id in stats['complete_ids']: #skipping ids if resumed\n",
        "            continue\n",
        "\n",
        "          if 'types' in q_obj and 'structural' in q_obj['types'] and 'semantic' in q_obj['types'] \\\n",
        "                  and q_obj['types']['structural'] in structural and q_obj['types']['semantic'] in semantic:\n",
        "              stats['iterated'] += 1\n",
        "              logger.debug(\"=\" * 80)\n",
        "              try:\n",
        "                  presupp_triplets = extract_triplets_from_semantic_program(q_obj)\n",
        "                  if presupp_triplets is None or (len(presupp_triplets) > 0 and len(presupp_triplets[0]) != 3):\n",
        "                      logger.debug(f\"Relation presupposition extraction process failed on data point id: {id}\")\n",
        "                      stats['questions_extract_relations_fail'] += 1\n",
        "                  elif len(presupp_triplets) > 0 and len(presupp_triplets[0]) == 3:  # hard validation!\n",
        "\n",
        "                      triplets = [[str(x) for x in t] for t in presupp_triplets]\n",
        "\n",
        "                      logger.debug(f'Generating for question-id={id}')\n",
        "                      start = timer()\n",
        "\n",
        "                      subj_has_multiple_presuppositions = len(triplets) > 1\n",
        "                      questions = list(chain(*[generate_from_questions(q_obj, id, triplet, stats['augment_stats'],subj_has_multiple_presuppositions=subj_has_multiple_presuppositions) for triplet in triplets]))\n",
        "                      logger.debug(f\"generation time taken: [{timer() - start}] seconds\")\n",
        "\n",
        "                      generation_summary(questions)\n",
        "\n",
        "                      # emit\n",
        "                      for q in questions: \n",
        "                        #name-format: {num_generated_questions}_{origin_id}\n",
        "                        with open(data_folder+f\"{stats['generated']}_{id}.json\", 'w') as nf:\n",
        "                          json.dump(q, nf, cls=ObjectEncoder)\n",
        "                        \n",
        "                        stats['generated'] += 1\n",
        "\n",
        "                      #mark finished\n",
        "                      stats['complete_ids'].append(id)\n",
        "\n",
        "                      # update stats\n",
        "                      stats[\"types_dist\"].update(Counter([q.failure_type for q in questions]))\n",
        "                      \n",
        "                      # save state after stochastic methods\n",
        "                      numpy_random_state = np.random.get_state()\n",
        "                      with open(folder+'/random_state.pkl', 'wb') as bf:\n",
        "                        pickle.dump(numpy_random_state, bf)\n",
        "                      \n",
        "\n",
        "                      with open(stats_path, 'w') as xf:\n",
        "                          json.dump(stats, xf)\n",
        "                                  \n",
        "\n",
        "              except Exception as e:\n",
        "                  logger.debug(f\"Raised exception {e} on question object id {id}, continue processing...\")\n",
        "                  raise e\n",
        "                                      \n",
        "              logger.debug(f\"Iterated=[{stats['iterated']}], Completed: [{len(stats['complete_ids'])}], Generated: [{stats['generated']}]\")\n",
        "              gen_ratio = stats['generated']/len(stats['complete_ids']) if len(stats['complete_ids']) > 0 else 0\n",
        "              logger.debug(f\"Generation Ratio(generated/iterated): {gen_ratio}, Augmentation-Stats: [{stats['augment_stats']}]\")\n",
        "              logger.debug(f\"Extracting-relations-fails: {stats['questions_extract_relations_fail']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rja8WMTZkmqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to GQA train balanced questions\n",
        "path_to_data = '.../train_balanced_questions.json'\n",
        "from_questions_pipeline(path_to_data=path_to_data)"
      ],
      "metadata": {
        "id": "191km_FWGAGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wzh0qP6TRPp_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}